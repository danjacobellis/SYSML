# Reading list

[Source](github.com/danjacobellis/SYSML/blob/main/reading_list.md)

#### [Paper: Outrageously Large Neural Networks: The Sparsely-Gated Mixture-of-Experts Layer](https://research.google/pubs/pub45929/)

#### [Paper: PaLM: Scaling Language Modeling with Pathways](https://research.google/pubs/pub51308/)
* [Google research blog post](https://ai.googleblog.com/2022/04/pathways-language-model-palm-scaling-to.html)

#### [High throughput Generative Inference of Large Language Models with a Single GPU](https://github.com/FMInference/FlexGen/blob/main/docs/paper.pdf)

* [Code: FlexGen](https://github.com/FMInference/FlexGen)