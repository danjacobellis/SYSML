{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1fb27c97-222f-41f4-b247-bc263e9b1df3",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "import numpy as np\n",
    "import PIL\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1b858890-f4e9-4f8b-91e7-aaea546e3978",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def display_tf(img):\n",
    "    display(PIL.Image.fromarray(np.array(img)[:,:,0],'L'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9fbb29de-9b76-4dcb-bd7f-68e5fdc67032",
   "metadata": {},
   "outputs": [],
   "source": [
    "training_dataset = tf.data.Dataset.load('imgnet32y/')\n",
    "validation_dataset = tf.data.Dataset.load('imgnet32y_val/')\n",
    "print(training_dataset.cardinality())\n",
    "print(validation_dataset.cardinality())\n",
    "for X,y in training_dataset.take(5):\n",
    "    display_tf(X)\n",
    "for X,y in training_dataset.take(5):\n",
    "    display_tf(X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b227ffbe-8b2d-48d2-9896-b42ce63a6843",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# From Apache Licensed tensorflow compression example\n",
    "# https://github.com/tensorflow/docs/blob/master/site/en/tutorials/generative/data_compression.ipynb\n",
    "\n",
    "import tensorflow as tf\n",
    "import tensorflow_compression as tfc\n",
    "import tensorflow_datasets as tfds\n",
    "\n",
    "def make_analysis_transform(latent_dims):\n",
    "  \"\"\"Creates the analysis (encoder) transform.\"\"\"\n",
    "  return tf.keras.Sequential([\n",
    "      tf.keras.layers.Conv2D(\n",
    "          20, 5, use_bias=True, strides=2, padding=\"same\",\n",
    "          activation=\"leaky_relu\", name=\"conv_1\"),\n",
    "      tf.keras.layers.Conv2D(\n",
    "          50, 5, use_bias=True, strides=2, padding=\"same\",\n",
    "          activation=\"leaky_relu\", name=\"conv_2\"),\n",
    "      tf.keras.layers.Flatten(),\n",
    "      tf.keras.layers.Dense(\n",
    "          1024, use_bias=True, activation=\"leaky_relu\", name=\"fc_1\"),\n",
    "      tf.keras.layers.Dense(\n",
    "          latent_dims, use_bias=True, activation=None, name=\"fc_2\"),\n",
    "  ], name=\"analysis_transform\")\n",
    "\n",
    "def make_synthesis_transform():\n",
    "  \"\"\"Creates the synthesis (decoder) transform.\"\"\"\n",
    "  return tf.keras.Sequential([\n",
    "      tf.keras.layers.Dense(\n",
    "          1024, use_bias=True, activation=\"leaky_relu\", name=\"fc_1\"),\n",
    "      tf.keras.layers.Dense(\n",
    "          8192, use_bias=True, activation=\"leaky_relu\", name=\"fc_2\"),\n",
    "      tf.keras.layers.Reshape((8, 8, 128)),\n",
    "      tf.keras.layers.Conv2DTranspose(\n",
    "          20, 5, use_bias=True, strides=2, padding=\"same\",\n",
    "          activation=\"leaky_relu\", name=\"conv_1\"),\n",
    "      tf.keras.layers.Conv2DTranspose(\n",
    "          1, 5, use_bias=True, strides=2, padding=\"same\",\n",
    "          activation=\"leaky_relu\", name=\"conv_2\"),\n",
    "  ], name=\"synthesis_transform\")\n",
    "\n",
    "class Imgnet32yCompressionTrainer(tf.keras.Model):\n",
    "  \"\"\"Model that trains a compressor/decompressor for MNIST.\"\"\"\n",
    "\n",
    "  def __init__(self, latent_dims):\n",
    "    super().__init__()\n",
    "    self.analysis_transform = make_analysis_transform(latent_dims)\n",
    "    self.synthesis_transform = make_synthesis_transform()\n",
    "    self.prior_log_scales = tf.Variable(tf.zeros((latent_dims,)))\n",
    "\n",
    "  @property\n",
    "  def prior(self):\n",
    "    return tfc.NoisyLogistic(loc=0., scale=tf.exp(self.prior_log_scales))\n",
    "\n",
    "  def call(self, x, training):\n",
    "    \"\"\"Computes rate and distortion losses.\"\"\"\n",
    "    # Ensure inputs are floats in the range (0, 1).\n",
    "    x = tf.cast(x, self.compute_dtype) / 255.\n",
    "    x = tf.reshape(x, (-1, 32, 32, 1))\n",
    "\n",
    "    # Compute latent space representation y, perturb it and model its entropy,\n",
    "    # then compute the reconstructed pixel-level representation x_hat.\n",
    "    y = self.analysis_transform(x)\n",
    "    entropy_model = tfc.ContinuousBatchedEntropyModel(\n",
    "        self.prior, coding_rank=1, compression=False)\n",
    "    y_tilde, rate = entropy_model(y, training=training)\n",
    "    x_tilde = self.synthesis_transform(y_tilde)\n",
    "\n",
    "    # Average number of bits per MNIST digit.\n",
    "    rate = tf.reduce_mean(rate)\n",
    "\n",
    "    # Mean absolute difference across pixels.\n",
    "    # distortion = tf.reduce_mean(abs(x - x_tilde))\n",
    "    distortion = 1-tf.image.ssim(x,x_tilde,1.0,filter_size=11,filter_sigma=1.5)\n",
    "\n",
    "    return dict(rate=rate, distortion=distortion)\n",
    "\n",
    "def pass_through_loss(_, x):\n",
    "  # Since rate and distortion are unsupervised, the loss doesn't need a target.\n",
    "  return x\n",
    "\n",
    "def make_imgnet32y_compression_trainer(lmbda, latent_dims=128):\n",
    "  trainer =  Imgnet32yCompressionTrainer(latent_dims)\n",
    "  trainer.compile(\n",
    "    optimizer=tf.keras.optimizers.Adam(learning_rate=1e-3),\n",
    "    # Just pass through rate and distortion as losses/metrics.\n",
    "    loss=dict(rate=pass_through_loss, distortion=pass_through_loss),\n",
    "    metrics=dict(rate=pass_through_loss, distortion=pass_through_loss),\n",
    "    loss_weights=dict(rate=1., distortion=lmbda),\n",
    "  )\n",
    "  return trainer\n",
    "\n",
    "def add_rd_targets(image, label):\n",
    "  # Training is unsupervised, so labels aren't necessary here. However, we\n",
    "  # need to add \"dummy\" targets for rate and distortion.\n",
    "  return image, dict(rate=0., distortion=0.)\n",
    "\n",
    "def train_imgnet32y_model(lmbda):\n",
    "  trainer = make_imgnet32y_compression_trainer(lmbda)\n",
    "  trainer.fit(\n",
    "      training_dataset.map(add_rd_targets).batch(128).prefetch(8),\n",
    "      epochs=15,\n",
    "      validation_data=validation_dataset.map(add_rd_targets).batch(128).cache(),\n",
    "      validation_freq=1,\n",
    "      verbose=1,\n",
    "  )\n",
    "  return trainer\n",
    "\n",
    "class Imgnet32yCompressor(tf.keras.Model):\n",
    "  \"\"\"Compresses MNIST images to strings.\"\"\"\n",
    "\n",
    "  def __init__(self, analysis_transform, entropy_model):\n",
    "    super().__init__()\n",
    "    self.analysis_transform = analysis_transform\n",
    "    self.entropy_model = entropy_model\n",
    "\n",
    "  def call(self, x):\n",
    "    # Ensure inputs are floats in the range (0, 1).\n",
    "    x = tf.cast(x, self.compute_dtype) / 255.\n",
    "    y = self.analysis_transform(x)\n",
    "    # Also return the exact information content of each digit.\n",
    "    _, bits = self.entropy_model(y, training=False)\n",
    "    return self.entropy_model.compress(y), bits\n",
    "\n",
    "class Imgnet32yDecompressor(tf.keras.Model):\n",
    "  \"\"\"Decompresses MNIST images from strings.\"\"\"\n",
    "\n",
    "  def __init__(self, entropy_model, synthesis_transform):\n",
    "    super().__init__()\n",
    "    self.entropy_model = entropy_model\n",
    "    self.synthesis_transform = synthesis_transform\n",
    "\n",
    "  def call(self, string):\n",
    "    y_hat = self.entropy_model.decompress(string, ())\n",
    "    x_hat = self.synthesis_transform(y_hat)\n",
    "    # Scale and cast back to 8-bit integer.\n",
    "    return tf.saturate_cast(tf.round(x_hat * 255.), tf.uint8)\n",
    "\n",
    "def make_imgnet32y_codec(trainer, **kwargs):\n",
    "  # The entropy model must be created with `compression=True` and the same\n",
    "  # instance must be shared between compressor and decompressor.\n",
    "  entropy_model = tfc.ContinuousBatchedEntropyModel(\n",
    "      trainer.prior, coding_rank=1, compression=True, **kwargs)\n",
    "  compressor = Imgnet32yCompressor(trainer.analysis_transform, entropy_model)\n",
    "  decompressor = Imgnet32yDecompressor(entropy_model, trainer.synthesis_transform)\n",
    "  return compressor, decompressor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "acd21483-8091-4f79-83d4-d72b1d0b1934",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "X_val = []\n",
    "for X,y in validation_dataset.take(5):\n",
    "    X_val.append(X)\n",
    "X_val = tf.stack(X_val)\n",
    "display_tf(X_val[2])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "864eefa1-c2b8-4989-9902-e6c7824b74c4",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "trainer = train_imgnet32y_model(lmbda=2000)\n",
    "compressor, decompressor = make_imgnet32y_codec(trainer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ea82e884-aac9-4952-95ac-f65cb0abbc0f",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "plt.plot(trainer.history.history['loss'])\n",
    "plt.plot(trainer.history.history['val_loss'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "003ddbda-2875-45c3-9c75-442a6513645c",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "strings, entropies = compressor(X_val)\n",
    "reconstructions = decompressor(strings)\n",
    "display_tf(reconstructions[2])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0ed08dd0-1a03-4b44-b4a0-86bdd965d660",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "print(f\"String representation in hexadecimal: 0x{strings[2].numpy().hex()}\")\n",
    "print(f\"Number of bits actually needed to represent it: {entropies[2]:0.2f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f0c6c8c5-9cdb-49f2-b972-1d1f6fe35e63",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "trainer.save_weights('imgnet32y_trainer.h5')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
