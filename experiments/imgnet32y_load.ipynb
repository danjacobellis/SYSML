{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "b012b6ad-7833-4eba-a34a-2cce64128ff0",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-04-18 11:21:13.287638: I tensorflow/core/platform/cpu_feature_guard.cc:182] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n",
      "To enable the following instructions: AVX2 FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2023-04-18 11:21:14.051640: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Could not find TensorRT\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "import numpy as np\n",
    "import PIL"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "205df3f1-cd47-4c2c-bc61-a4bbed93f653",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def display_tf(img):\n",
    "    display(PIL.Image.fromarray(np.array(img)[:,:,0],'L'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "13ce807a-b34f-4257-a36c-40d8fd391b51",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tf.Tensor(5, shape=(), dtype=int64)\n",
      "tf.Tensor(5, shape=(), dtype=int64)\n"
     ]
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAACAAAAAgCAAAAABWESUoAAADrUlEQVR4nAXBSXdTVQAA4Du9+6a8pEleM7RN2gwNbZEOCNSCWz0U/oAuXLhy5Yp/4C/QlSv9AT0HlyzwCCpSezjY0+FEpIWQDqQ0TZrpze/de/0+mJRSkeUGsgQAEgIDIC4ZELovJ7jgXECiRr0AEII4RAJAJiCmHkhIjqtQCMcsi0Qcy5FKfF8wzCFEAFFfjrchBQhCnRCYYxgk72bCjRZESECEOLgEOEASoVyCiJEoShVra0TmP8Lx0uCQ25xj3aNTIugyNcCcQPUzPFVGwY0HJwstLuocxJc+DWMm9zY2/UBAOH/HSs9V8mf/oBRXp9sfmhUpeRLRhK6C35/WAYRfCH1N71LSpXLHXTEusGFpTifnZJ/PnU/8cHqOkMgkKleTGqOq5nE3m8uXS355QvfceEv97p6MHHn5Cj1QzMAfglh+JT1jDH7elEuXG92HBbkZqQRTUzmWL/puq9fNb5rIe1cf6LajFT+cjMu9M0xi9Nic2W5nlNzCIX06uTVfdaKY2UhUtQU/aG9R+I1sFBZ/HURZzfbrxzDvpt+Cr/mcS8LzF8Ef7RhcTyFjftcL1RJ8WVpqWigdb7kpBSlG87fXfYDIoQTADhbc/9tGQB9WJxsTUnOzF78h/2d4HDHieyR0eMinU/dHZkZ5cj1ztLMX+ec3g+GtfYcDNLBGrut44effvnPHR2JqJ/4qmU/GynXqb3kQcER8x3E9kf439RXc771fXg9riWLI6Bs/ixyMIMzaAhPDhPOiLLeVfm/24s5R47DyTM+lG0ceE0QNKTE0fpFExZTZ3iRviyO8D5ycvXRlufbwESO5SA9DjVUso6SRIIlO+rpjkQKq3mxbnRkJorSw+n1WhpT2O2eNVhvXqiiRaA5be69fjf7EGnnwJeNjojccG9vRu5W7R+D+9Da62lTc82hVLyCdvLBBdfVZG4yS9yrI3mkq5HHH7qhB26ssJw7YiPykBYsOkyKt9jHZf19XY38dKbqUpoh0G6sDSIj+0WIH66ExiR/z4yFNZOe2z7ykydHym9ldlyHySS0M/ZVdbc5v+mrWrFxXjL2DhGAr3m78ucsCAj2Xn2YkFAWExcdvL1wqSx3JEZOT38cehQAEJOhEQ2IvDPgAFPKz11gc9kU8mph6cuLKsso0kvGZChUdNTPrqemhBzDDS9ZL1ftlpAGh0z6BZBR5l4PCrdtFHAMCM4J5/xr9YKBT0/W0OFGhi3KyyK0FAyJIIJP28MJPYg3rGssh2/4feY/X0xmnPnAAAAAASUVORK5CYII=",
      "text/plain": [
       "<PIL.Image.Image image mode=L size=32x32>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAACAAAAAgCAAAAABWESUoAAADW0lEQVR4nCXNX2scVRQA8HPuPTOzOzuzu8kmTRstKZvUWqU+NLVQFH2TgAR86ZMfwS/hVyj64rMoKIj0SVCrCNWKJcSgppRQ86/NbrPb7N/ZuTP33nN88PcFfogggI2mFs/eo0Nm9iLtdXfvw+DPZ7hMAiji6d3VM9v3aeog4/L4oYLCL33ZVe6UUADA+1ff2zoK/nltvb6wYKK/NsmX8N1eQLWxAhAA4aLeeWTyr3eKn7YX9ADJFfCwkly8qQgAAJiLTj/9+4vbp4O7H3Q3QBOX8dVrUX4IChAAANy/t4Kxv2yTz33rbEDKTKorjVj5NQUAgALF/vVcP1i+NPoxu94sVfFioFfyyaBa/78QsNH48O2DtuSf6NupBQtlmuIJpxcJBAUAytlv2Tu2NZ6eO8gunKJ43/msVU+bEaEAAoox3aVaFJuvcg1E4FygYGjqXSYEAUQxe7QefnvhCnQoND3tfDQXRmkLQQECaoTioyjI7m1nIQaDwqJ3zjGH4kuFgC9vXq2Y9XZz5h9Nes2Pl7pHUtgV4z2iBRU1Vzdbr1cn7vwvB9fWnk7f/yE5NGyx1boRzII0oDuDcLazM4adm0/ijf3Rrbfubg8j5jAf/q57iTCZuJhmSa/3aem3rXXuV/5ZDVgYTFbtt0Mmp6SrR7n6Q3snSWMfAwwql59OXTiMit03O9SrnO25yPuZ9h6tLdEiVJe3aNhQ8eno4Iz6lF76vo1i0pkDlYsg8PyurewuD0PtTjzdvzKsFhj5YHHjmzhgBCndeIjGPmtmgcoVLXbLRmyYIrtVR1LeyxwstR9AQ7MLUAy1s/sTl4d1HilWuSKlCtlPNWjSVlDVqTixtrE4PauRF9HeCWAy6+ucrLWoBXBelUuV5DGqkD0pq0ABZlpsCDiuKihVUgnMiy6JsxyAJw9SjaUwCtFXblSwJE+JdaCctsSq8Mh6zBo8euSoz+eYmjjjwEkAUOQQKVTKlcLoULksKs0bhBBFuRa3MGenReacAVSAIsAC45fsGrECarb2dWvlcZyocByBzCx7ZgbIq609AtT0ynx6eGSKuU6RCjcWnz9X4jUW1lK5SoJyfnkUr/BxgCEE4SyuRYAAVDMTG3gkAJnUou7xE5WX0QIyQVhBzYDWstbU+Q+vQOo9iz6DsgAAAABJRU5ErkJggg==",
      "text/plain": [
       "<PIL.Image.Image image mode=L size=32x32>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAACAAAAAgCAAAAABWESUoAAADpklEQVR4nAXBS2wbVRQA0HvfvPl4xpnYcRPn71qUhDQiqUSgSiuQWomWRaPCFiGxYAOIJWsWbNghVuwQCxYgsWBZipBQkRraENK0VNCE5ms7jhN74pnxZz7vvcs5mI9BM1B/9+D8M1Ni2nXU1ikSI0Ig/GjuR0664IiDj+ZntUSk3SjJF08JoOARAJ35AScARD2dWGADfeBeNnW1/xKiJiEAeL8jVwCC6ypttu2MG47FqPEbBweUZRP7A4ULrQ6XVvFYMWxXJrV9ww65LrvhqbKHiovlkytD1ZRlM5FBYT+XZwLkSHp2QbTqQSaNMteLDVM0PD5fGsysbqpqb6a6lSvdT+Zr9e4whGRTDsZ3GoK3LrtRX0nvYrhnbWZNqJjReb2pXLn2qNvcOi3wfNBJhhS/KZxpa2r55K+enTHtjsy3fg0yDVE2GWjgFLVLU1rb7cUpH9RcLQgixevNbsmXlsull9rhwOSTmpuMH+xYwycjwxkrrm35rhrQ+kzn7vBxGM94eJ5vDxwcc2YZYbZROc1Gmk3R9LLOXns7ruFLl0fkaKferjT8wxrvczIMK+bp3HvjJi/05sT4YtBkC9TPhJ2gvGrCkB1pJlHxStiWLNiqknCbfrl33R+MvaKUDFtOjsdOejMKWIu7FWbNNowXLuTcc5XnA2ndMaEZBqpjfz560s9PcC9xivnuK91d/v7De/6UMVPYqGVQdMd+ME990Dn3bV1sNnar9OU338vyks1ZeT2rF71PD51O1D0a4XJ3syUUDs3e+Cp3ddyS3PIoGs6VChtGdb8WrODryUFCpPBr7btFdDRN//kPZr4xmASVNuYuLU/xw5KQCGRN/nJRl0KHb/dQGbl8vOssTLRvScbnOwKRaClcXZIMfltPEGHs1Yr9Rf2em2k9GGNO/s1rnM6t7FQF9H/aQASiwoQZrG2LmqrJ+5znHGj+bS/c6Rw5a2dSEAGqjc2TtU5bfhgmJZ48dQbz197y78JWIwVJhKCCh39GQIr8s0zE/bB3bHxsPn7uHkXATBWDAisbEQLKykizykfjnHn4mK+vnBweCWafkUS23wQEJLjzsmXwBRGJ4shT2AiWay41FSBCnXNCIg7/DBHL3trcnr777ztpmFpWKogxJNIAidDF9PiYp8NTtx/sfSA+e9KZTnwGiKRYwQMgCnRLaUwPPqnUu0XDuFroYMwQAZB7IhUK85oEyRz52HjRKfSiZ09CgYRI6JQFMU3P2xxR/g8ct/rS1dF/OAAAAABJRU5ErkJggg==",
      "text/plain": [
       "<PIL.Image.Image image mode=L size=32x32>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAACAAAAAgCAAAAABWESUoAAADYElEQVR4nAXB2Y/bRBwA4Dl+Yzs+E2+ODaSbZakQlC5qBa2ExHufEH8g/wSPSDwgnnhBLEItFY3QbrKby5vLjicej+fg+/CP7cMbJZutvnu42r2aJsNDPr7Z9Y6jHN9mqXOEi68XCHEz//hqvx61sOTmUnnjSbTItpBwzwPvQCcp2WN798zzkgDXchJ2uCpsdkofBicAfuN0S1/uoleO3ouxDMrW6vpx+F885rao9gE0edu08iu/Nx9xPgaF0j/P3z2GL9Z3PXTZ/EvgMawaV72PF0NlO7FZJfLL3e/RP93TZBc/JjKB++vKcTPd+UTNzoZu3W9gnnd/4mfuKOi1xz87hB0wreT1wS0XbzlxobPWk7f4CbeV2lx+9YySfoEyjlbFrcUX9G69yVj7YuredS4qQi8y68GhjAtuq5dBPqi2RzF4eiO6OY6eh1ilWZa7IPyqX5LPnqhKV4uZXv82vZ5h/TxN70/zJkkDEE/3G8b+qrO1t6seahTBHzNCj1Mv5cBR0kC5Rp7+AOez1W5DTRnlpTaAik4RtzF2KAXHhMeMdX/NpkDcktSIVhjEtqeOPqUudiDcb7Yzv1IuUo0gChTRxEgTS4V9RiyC4aKYkh1nHgiFpIWwIk1Bda5dagAZQgq9H3WVpxZVSyugvgJLmOMY7gKzxihY6+/2Cyba9Y3q6FgfDcEMiKw6yq/Rp3OAXTJdkpM5dJO60YXEqCYIGTeEuvHFMiAkKCf1iCGxT4AxkNgwipBOQlcDDnRtgehh8aHlGNGHE9ednU+R1DSVyqQWu1hDA2Wr5YmjYCr6Qr/3OlxiJxXWom1EsVPBlpHGURaXzD3EL17+siydcHAKbIuDBWkQQUDpZr8GV17H9zvxJoRey8W01sw6jsaKnPu0pjzSnlvHzt+c//DN6HtCCqSo71MjBBDh1aOlqvU2zkPnYSzGPnq9XPSNSRk4nBHu2G7+YGwZ2vN+HVOrV9ts+USkcn+sT1qR7YYadhYqGjTzwq4QcGKV40TYPwpnxwWpqcu8z20aBG1vcxKnkgJuxbpV6zJKlDaEDciZj3RCqi0O8BYksbrkjeHNEd2HmJJhvlhGD0pGIkIGBqKGRsrysLbs21BXVkJeMBu8llA32KJ3iTJN3SBiJXM/2lzeHpv/AU+pCeDNHlOLAAAAAElFTkSuQmCC",
      "text/plain": [
       "<PIL.Image.Image image mode=L size=32x32>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAACAAAAAgCAAAAABWESUoAAADc0lEQVR4nAXBSW8bVQAA4LfNe2822+NkmjRJ0wQiaEFCPXFAPVCExIkDByQO/Ch+BTfEBRWxqCgghBANbYnaptmdOE6827P5rfP4PngsLBV1AJC1CEsmg2L3tc47fUi+/mL0zZwiw6zQraiuLUeL0MVDyq3AqnZoozVLzTLJUJhDqbVhhhuwMG6hbz3r8oCyQpxsZYIQa/3GgBNExjG6wHM+bw5hPZHJzpaZNtUZalCMRyEDhWhhFGGaZN/2JthXnXvbT0D3ZUwgJwgqRSMq2KUXBfMeejXNAcGCTflZ4lBOqdUYKlx4izBqgujjT0oTEC/Qvx2oJZYRrwCKYaF7LdtbDsf7AfoTVRTilUaZD4YqI5JoL0scbUwaa+BEuPzJKwgopK2sKvUMC6IFFTXkNnAUHf/dnvX+XUBTErpZuC07h5hwrLQvs1QxYb/r+fxchLmmVXT7/P2nuSA10SaiEDQPtwN7sA+aG9lqXhLG/G3uZ5lQjqDAs4UzG73+zgvwVnPFHY+VljS7c+f7PtDOJ0TJK5nfmV+fr42BOb+H30jg2TLq+i8D/3S5Ra7aQ6mNEfKjyIqnwM/SvFC1A9lwKCLI+mREBmy6dLb5butQQLYzuCJcMYCd9pODGR4odHmw3+V1GtS2DGjLaZIUQNT+0j8bPDS1hKTs8TrlSupJ30/G/cSNZFCrUvy426bYYYue1482EwRKTEeNRsN0xobzuy3PmdkIEGEB4fl1G4ScVV42xcC3iPB1wqzQIK8WECfk4fjoIUYyJdbaEsDbIx3ThFyk3LvhQsZTdJcOinMU2PpShqUkrYaffPnZSBbr5YMtXM0EIpv0h2ckEETbsnRgDqK1ho6i5XdWP0U+UhBtKtJJhqdTj61Pw2LUteHNdV2Q+/7KjpcmyCFyf9nt/X6ZyMnYWKRtbtxfEyb8fbEbvxe1Y2JmMK2e999Ol8dVBT2weN2qVnCp6Qtx8SCwAbr4tROuxvOIrkUxV9RAuygPB/UbPq+aHRUD9MvR8IOvVuoT3IYj4TmjGMwLK//bs0e3+jenHXKgeYofPf4pnfap9SQ2ujnpSoMmSHUNQR7Jwnac8qh/YlkNIUC4RnFFma1rlCMPIAQkUKj1ebrXUcRWmBMsKYMIQI9iZGuFcDz++Q+z8uH0pLKep3OBncQMOoebjHqQ/g8TZP0AjZ7oowAAAABJRU5ErkJggg==",
      "text/plain": [
       "<PIL.Image.Image image mode=L size=32x32>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAACAAAAAgCAAAAABWESUoAAAC6ElEQVR4nAXBz2ucVRQG4Pecc78vM9NOk9DUJBWxVRoQpII/i1a6UqQrwZVCV936BwmiILpzL5S6sN2oFBR1U2xNaSxNSzBNJ+lMJvee9/V57LPFQKtHsw8GT3c3Osv9yb9b93yxzj9dz8OfXeWIITPDYGFrZfKc5Z3bJ2ZvPjjz0jnN3Qzu+9PaEmVIXxsPlHj7/OXNX0c/3oxBXxAR5WmvzmA9/MzMzHT3n8nLgzjPGxcCblCZFIyiRFjMDrCodu296VtaeLh9uHfKFTCfTibT+bxWv789eryvP0aX/h4/ubl88O4LiAKzcvQsfNA3s9FxrsfuL1fw2v3fVx5+PvImD6BUeGSN5LBwceve1fGzB/XF2xcdVtINsMsq/bCTPhy7pEh+/+rm2fO3/jr5/klNrmPFvlQhnX6yB1sgfWhH7Zgf3N65pCffnr5QijllbmbWBCYyTIr+DcwVSxtHpUmAvEwtdGfz8UEwRuNzr5T0ZHunuP2ZZDZFz+2vdmThclHl4sdhpNLKSIBBoH23a311E0qjbow+MQiUp5it1saWHvCMwXzeYPWnWueZUClGyYDYqbTBrKUcki9wfzXE9BIhsjOLbTT8V33e6Iw8vXT9ioRijpQCMMxOD1qKR9Os3nB26doPEQGWb8bHx8uLx473s1P7C6xQZ7UM1k5N9r6efhRi+U1JJRbWXrf0EWjWFOq74Y59cTerSks0svdnGVfJcJoSdHSDw9mjEbzQWRrNeqDQAik4zRTDQ+65oUzNo7W+UjQoJSMTALuZPSnWlY4BpNEDYDplRkDQic72ng+WKCI6c6e5w6ORgIQYpTU2L0STOlg/CIMECkiJWBIPD8wKpHQ2La+JIkCCKadWaSvNrcxBN7qyugiTtwRAT3BprESpVtFbKwKKKOfCjDA0tuF6QfEyNQsGauscpqSrrwK6lquteaKQ7pWmW496M2aTYI2gtr1ZU9oGrZToDBRE0syMzOIOZZP9D00E45k3sG3WAAAAAElFTkSuQmCC",
      "text/plain": [
       "<PIL.Image.Image image mode=L size=32x32>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAACAAAAAgCAAAAABWESUoAAACt0lEQVR4nAXBzY6eYxgH8P/1cT/P+2rN1BSTFjEJIcQsray67cIRcEa2Ns6AA+gZSIiInQidZCg2qtV5P57n/riuv99PPrsLkmTl8ccPrz56cv+Om5mpAKY2qmcRkOSvp9PHz9/68+SOm5mLiEmJjHS7hUyQ7336oDz+4u9zd3c1mJqmtNz66QlHQC4fKvDu+6ACJF08s9nM7ucbJo9nDxUgt/HPGyCRwiRnETW/y6w8+VwBfPv97/lmKNMsZs5UJYu3sa7lwRYAPpm/yWFFXc2lFCi1Qh1VlwsAwF/LGTlpmedp2rgWK7EtroK4vgWAzx5d1SLqJpOpTENhtooLsLl8vsXy5OubQ95WLzNEpsxt3zSZmqqI/HaFw09f/vzLq8ZQyck9J2UZxVQ9KVfy1eP9d/sPrq/PYVYkXCxLnwlJ0WDeu/fvox/uL//dvjBKZnFqEoUwnUw5bPvHJV47u6g1xc0Ugpw0VUq0VTXZ1pdeydfl7dFEIxTJKfoMGy2m7VG1935+c9Ei9wAgVGXd5qqHOXFzFIX1XLMcDusBvTIz0+NQGuUFqzR4rAiLpOSL006IcrRNHKfdNipyrV4xFAmSL6aVYZ6zHrZDZF/2ok6PtZUQCcRuaiJ99WXyZWoeY6q7snqtEROTuBGXYBRYT+9kNjoW+NLXsiiJpydNGEAzZ6h0z1znGr7sWhiEePpyZEIGGAUiskiP/WbxGtUKUvHsnUaR7BAfmxjSRbT18LqucyiB3dyVTCtJtsJEBe1gXuugqbDCBpEsw8c0OlIywkbzPnqmUnZlSBIIDu3zQITk6L56a81DKUdvQhF2qrJ6yAjqyPTeAyrCJl0syaoszIGQMRSreh+DosDA0IGEijS1IZGSrWR674OaQOQQkhpplKbBTMVSqrceVAUkByDIwbAEAGS3MfA/KGX02L90CRAAAAAASUVORK5CYII=",
      "text/plain": [
       "<PIL.Image.Image image mode=L size=32x32>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAACAAAAAgCAAAAABWESUoAAADPklEQVR4nAXBS09cZRgA4Pf2nXPmBswALddisSoVYtQQknrZ2F/gzrhw5b8y7ow7F8bERJddaDRGkwY0EcqlIBQGBmbOzLl+3/v6PLgpSfvFqweP9+ESinbkCimhxdnSVozwHVIgZuZKSpKxkmu0I7HFSTm12mYmRB+UiIlrKzgE75kiD4gMATNEEjEQYmYGMvFZDLHPO+IQk6YM74gpokiIiYUdUBsZmxZ6LiZkh/UrJQykgYSJpfbcSQTYMXfAsLwpuS1EOh2rEBIJGuVoPbZif62jM5KjsSCEgSNCQuJoxY81DCC36jyvoKdZMAAEIhIEQK6oXwQ0/9pmfTSoC/PIagSAigIAxhHnrRTZJeudYZG5CzPsBwZzIci5b3WnDdNW4knvpXL/FNKZCXMP0QIGpHQCPLc2vTj/tIWLq0ujh3MxFGi2zmZWK8t8lsx0Oc3YPnhmCbmoyZ2AYBbQAvtIcu0sxbFdFJy8//KPp42rI+mxSy9/f0KmoCJau2w1iuZSH9WX13vNi7q3HR2cnd1NgKwxbIqxjWB6RkZV6DcnY233lt2Iz8Cqchxr18ntdH3ceHdKZ8vhPeT9+QU/7OuLG7DDU0yUSZrtenDW8fMr7Yl21u0Xj313OAS03NAVZISxyWgU/CibXKUYrUI/PzgeIaBFLQICychLNazKLLtRp75zbfpgkfcvccpbiCIiuz47eONtnOJUVz7thqZNhRC1P1xyG4nLSjAJKUn30VWelMlgY/L3x6vD3/z4dPlJqiNp1hAEAlB3++Q4nj26nMtZdpbivavr/x7u/BWXimyCIZa9+J3u80H+ydG/3Ggkt83tst4cnbTN1QoSxSJv/fDRg/r5Y7f2c/OWroa6NZtf7Do1UwySMG6svdm/Ll5feNk6L6t0A8zizB1HIUF1QQhoaa3Ll19/Md04vxv1f43UBo82DqvYu9KMCRB6EkJj8cf+5FsIXsd5OdiC8ziEAKhAADAFqrbwLPsmbVV1YIXPlwe7oIiqQUXJMj05P4irr8bQEQu123lPf3IySaRkDGLKfx4XQpD8c19MDSH+0u1ORBtRAK2UzOxKg3a2lwugGx8w+Wy2+f0QLTYjiv3/RxvN0M3XYFUAAAAASUVORK5CYII=",
      "text/plain": [
       "<PIL.Image.Image image mode=L size=32x32>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAACAAAAAgCAAAAABWESUoAAACoklEQVR4nD2Ty2pedRTFf2uf891ya0htmpqkDmIHdaBUSx0ITipephUnvoAP4DP4AI5FKg6cCFLBgRdwEHBgK6WiVKEIbdKmtA1q269fvsv57+XgpC72bMNiXfbWlxICROTGLsLC2AaDM0KHqFyNjtQRFQgkVMkmIlRFFRFofty1tFcFIahULFGHZAhHxjTdUx6ESaS0bBQhRb2rykH2lruONAKnsYG6AnsmKyi91cH+3xNsogABLnUYVJDLUuW5RZrN/RXjMGTaDkWE1nYjoqcymi2Mj98KhXAWgwgwHLuLOsOHl9//8/H642ndzUzTIsBJ7k/VaHLpzs5no3ploaSf7hWgUJz+kexc58ig88Wk25SZhGQ7HREhl+cfNPJPj9hbvXZnqbO7XDKbYimqKCXT+Pw2/WOLT848+uvn9asb07kKnJmlibRts753Zda9oR9ur3b/6C/GaBYCA0EaRZZ3t799iWfr3uTFJ1tNdz6aYsl2GMvF7nyw88zZm89d37j1yoTJQYBLMdY3UrZkit++z+GFtyb/TIszVWzs+rATjPP02a8ffH5qbRpZcAmSJJxpG9t2/+KZYedql3Tltm+o28ASLPbMm/OfnDxuHCUyLTLAGEAaXjq/snn0vYvXZCuMZEdgkAHzafdoOrde/fjfKtJqqcM4Wxuj319PZ/qNCx/dj0ppENRY7Y3r3qm1xO4sfxiX516TSAyRLm3a+evLB870tFp5++HJ727s3B0ChLO1aJ+bv4ntZrx/4p1fzm1tnlgA0Ff5VCPcawbLZD9euBLDgUinqfPQpYFVY0Q16UwH7e/ZdeK22HbA0u2l+4JWWl2k9P+FGXkydj9lTGLXqSoxsgU29tzGorZBrfSoVNKQltME9sFYs35mKSVLyf8Av5LKyQx+N6MAAAAASUVORK5CYII=",
      "text/plain": [
       "<PIL.Image.Image image mode=L size=32x32>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAACAAAAAgCAAAAABWESUoAAADXklEQVR4nAXByU5bVxgA4DP85547GeMBPGAwSWiA0qJGaqRIWVTqA2TRZ+iiz9VKfYBusu4m7arZRIpCKUOCwRh8r33nM/f78M8u6I+Cv6p8QX3PIwyAALgSpjEi/S9lAXRDl5a+estfvr8N4tBga4jnRj41bODvpn2CXH948fHmNVp2pqJJVs0j79D95XaTb/OqjEJyef7hOq6/VONqgg8a6n9WeLFn22r2FT5Lo1YXfpqz89kTdXY046xHElUU8sQkk9ke/UCHyDESDSzfng9VGuiW2MH1etWx2+kW5zY7rq/nOXmwfr/VhGEWy4Dk43WRHUvLRsNeeQAX/acTcjePwqZqloR4mnvhQk07Ru3cd8R1eP78+42APG/PE6ge7tWqJ9sIdWCsQnF4NU88ujhIL84I/7pVmFN+8im7P/RMa4AG6TS3s1IO0XT2X5RAkHcTydu8/66SwwHz3f7V3s4Ntj/G0j72JCNGKahQmW+9iKDtJ5uxhTV9lL3ZfC42uDciGOu7LrqdmQleXy3wEB6G4X29r/++eGBgaId4LhMi3fk2Z13jT4Za4oJ3mw13dMRvU+RRCHAJXrdbYIaxqfJz3U5mpqMdhoFABdsEX28Rp7LSiqxZAnJ80YXtNQkUKUOBUA1BtUxOaxrmqeCHdlXBJRS5N3uJ5+kxjUIMVWtcALv30edIPta1jLJVv91G78bFbjY/CTHp9r4jRUjyvNU5pBuKtzAGl7PR8PhUTwNDoZew6TLuigZntHeZxVzrhR4MBk9crZ9SJfFNZeQfcZi1ZD6vK42wG775VQUvukb8EEmo8FJasfzzrk1KL801ws7+Mnn87eZIDl6PYklKnEJl1vHlv7nd579ThNyzN5thsxIQEsaRLgFJZmPvcLcsm+zoE0HilVZN5XsIEWSRbIjQhEaErMpa0288hyZegGoAipG1ToqGVE47hxoeMWzosWueyQJZobQjxkhZ11BRhY3SmGDM3PgfvYN0YaxhAbJIiryCheWYNsZJpYQD2hNWKGSwolwJ05QCEhwCNc5WtTSOxExbrwRrPCxdpQotoCQyZI4KqY21yETaYWStc5KbRihRAwuZxdx64KGCgUIaN1YiTImQ0pi6htxRn/nYaoKllrWoKVWAELbWSG2k/h9mWAWphY5nVAAAAABJRU5ErkJggg==",
      "text/plain": [
       "<PIL.Image.Image image mode=L size=32x32>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "training_dataset = tf.data.Dataset.load('imgnet32y/').take(5)\n",
    "validation_dataset = tf.data.Dataset.load('imgnet32y_val/').take(5)\n",
    "print(training_dataset.cardinality())\n",
    "print(validation_dataset.cardinality())\n",
    "for X,y in training_dataset.take(5):\n",
    "    display_tf(X)\n",
    "for X,y in validation_dataset.take(5):\n",
    "    display_tf(X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "3b4e73bc-84a8-4568-b1a0-e43f0a1bad57",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# From Apache Licensed tensorflow compression example\n",
    "# https://github.com/tensorflow/docs/blob/master/site/en/tutorials/generative/data_compression.ipynb\n",
    "\n",
    "import tensorflow as tf\n",
    "import tensorflow_compression as tfc\n",
    "import tensorflow_datasets as tfds\n",
    "\n",
    "def make_analysis_transform(latent_dims):\n",
    "  \"\"\"Creates the analysis (encoder) transform.\"\"\"\n",
    "  return tf.keras.Sequential([\n",
    "      tf.keras.layers.Conv2D(\n",
    "          20, 5, use_bias=True, strides=2, padding=\"same\",\n",
    "          activation=\"leaky_relu\", name=\"conv_1\"),\n",
    "      tf.keras.layers.Conv2D(\n",
    "          50, 5, use_bias=True, strides=2, padding=\"same\",\n",
    "          activation=\"leaky_relu\", name=\"conv_2\"),\n",
    "      tf.keras.layers.Flatten(),\n",
    "      tf.keras.layers.Dense(\n",
    "          1024, use_bias=True, activation=\"leaky_relu\", name=\"fc_1\"),\n",
    "      tf.keras.layers.Dense(\n",
    "          latent_dims, use_bias=True, activation=None, name=\"fc_2\"),\n",
    "  ], name=\"analysis_transform\")\n",
    "\n",
    "def make_synthesis_transform():\n",
    "  \"\"\"Creates the synthesis (decoder) transform.\"\"\"\n",
    "  return tf.keras.Sequential([\n",
    "      tf.keras.layers.Dense(\n",
    "          1024, use_bias=True, activation=\"leaky_relu\", name=\"fc_1\"),\n",
    "      tf.keras.layers.Dense(\n",
    "          8192, use_bias=True, activation=\"leaky_relu\", name=\"fc_2\"),\n",
    "      tf.keras.layers.Reshape((8, 8, 128)),\n",
    "      tf.keras.layers.Conv2DTranspose(\n",
    "          20, 5, use_bias=True, strides=2, padding=\"same\",\n",
    "          activation=\"leaky_relu\", name=\"conv_1\"),\n",
    "      tf.keras.layers.Conv2DTranspose(\n",
    "          1, 5, use_bias=True, strides=2, padding=\"same\",\n",
    "          activation=\"leaky_relu\", name=\"conv_2\"),\n",
    "  ], name=\"synthesis_transform\")\n",
    "\n",
    "class Imgnet32yCompressionTrainer(tf.keras.Model):\n",
    "  \"\"\"Model that trains a compressor/decompressor for MNIST.\"\"\"\n",
    "\n",
    "  def __init__(self, latent_dims):\n",
    "    super().__init__()\n",
    "    self.analysis_transform = make_analysis_transform(latent_dims)\n",
    "    self.synthesis_transform = make_synthesis_transform()\n",
    "    self.prior_log_scales = tf.Variable(tf.zeros((latent_dims,)))\n",
    "\n",
    "  @property\n",
    "  def prior(self):\n",
    "    return tfc.NoisyLogistic(loc=0., scale=tf.exp(self.prior_log_scales))\n",
    "\n",
    "  def call(self, x, training):\n",
    "    \"\"\"Computes rate and distortion losses.\"\"\"\n",
    "    # Ensure inputs are floats in the range (0, 1).\n",
    "    x = tf.cast(x, self.compute_dtype) / 255.\n",
    "    x = tf.reshape(x, (-1, 32, 32, 1))\n",
    "\n",
    "    # Compute latent space representation y, perturb it and model its entropy,\n",
    "    # then compute the reconstructed pixel-level representation x_hat.\n",
    "    y = self.analysis_transform(x)\n",
    "    entropy_model = tfc.ContinuousBatchedEntropyModel(\n",
    "        self.prior, coding_rank=1, compression=False)\n",
    "    y_tilde, rate = entropy_model(y, training=training)\n",
    "    x_tilde = self.synthesis_transform(y_tilde)\n",
    "\n",
    "    # Average number of bits per MNIST digit.\n",
    "    rate = tf.reduce_mean(rate)\n",
    "\n",
    "    # Mean absolute difference across pixels.\n",
    "    # distortion = tf.reduce_mean(abs(x - x_tilde))\n",
    "    distortion = 1-tf.image.ssim(x,x_tilde,1.0,filter_size=11,filter_sigma=1.5)\n",
    "\n",
    "    return dict(rate=rate, distortion=distortion)\n",
    "\n",
    "def pass_through_loss(_, x):\n",
    "  # Since rate and distortion are unsupervised, the loss doesn't need a target.\n",
    "  return x\n",
    "\n",
    "def make_imgnet32y_compression_trainer(lmbda, latent_dims=128):\n",
    "  trainer =  Imgnet32yCompressionTrainer(latent_dims)\n",
    "  trainer.compile(\n",
    "    optimizer=tf.keras.optimizers.Adam(learning_rate=1e-3),\n",
    "    # Just pass through rate and distortion as losses/metrics.\n",
    "    loss=dict(rate=pass_through_loss, distortion=pass_through_loss),\n",
    "    metrics=dict(rate=pass_through_loss, distortion=pass_through_loss),\n",
    "    loss_weights=dict(rate=1., distortion=lmbda),\n",
    "  )\n",
    "  return trainer\n",
    "\n",
    "def add_rd_targets(image, label):\n",
    "  # Training is unsupervised, so labels aren't necessary here. However, we\n",
    "  # need to add \"dummy\" targets for rate and distortion.\n",
    "  return image, dict(rate=0., distortion=0.)\n",
    "\n",
    "def train_imgnet32y_model(lmbda):\n",
    "  trainer = make_imgnet32y_compression_trainer(lmbda)\n",
    "  trainer.fit(\n",
    "      training_dataset.map(add_rd_targets).batch(128).prefetch(8),\n",
    "      epochs=1,\n",
    "      validation_data=validation_dataset.map(add_rd_targets).batch(128).cache(),\n",
    "      validation_freq=1,\n",
    "      verbose=1,\n",
    "  )\n",
    "  return trainer\n",
    "\n",
    "class Imgnet32yCompressor(tf.keras.Model):\n",
    "  \"\"\"Compresses MNIST images to strings.\"\"\"\n",
    "\n",
    "  def __init__(self, analysis_transform, entropy_model):\n",
    "    super().__init__()\n",
    "    self.analysis_transform = analysis_transform\n",
    "    self.entropy_model = entropy_model\n",
    "\n",
    "  def call(self, x):\n",
    "    # Ensure inputs are floats in the range (0, 1).\n",
    "    x = tf.cast(x, self.compute_dtype) / 255.\n",
    "    y = self.analysis_transform(x)\n",
    "    # Also return the exact information content of each digit.\n",
    "    _, bits = self.entropy_model(y, training=False)\n",
    "    return self.entropy_model.compress(y), bits\n",
    "\n",
    "class Imgnet32yDecompressor(tf.keras.Model):\n",
    "  \"\"\"Decompresses MNIST images from strings.\"\"\"\n",
    "\n",
    "  def __init__(self, entropy_model, synthesis_transform):\n",
    "    super().__init__()\n",
    "    self.entropy_model = entropy_model\n",
    "    self.synthesis_transform = synthesis_transform\n",
    "\n",
    "  def call(self, string):\n",
    "    y_hat = self.entropy_model.decompress(string, ())\n",
    "    x_hat = self.synthesis_transform(y_hat)\n",
    "    # Scale and cast back to 8-bit integer.\n",
    "    return tf.saturate_cast(tf.round(x_hat * 255.), tf.uint8)\n",
    "\n",
    "def make_imgnet32y_codec(trainer, **kwargs):\n",
    "  # The entropy model must be created with `compression=True` and the same\n",
    "  # instance must be shared between compressor and decompressor.\n",
    "  entropy_model = tfc.ContinuousBatchedEntropyModel(\n",
    "      trainer.prior, coding_rank=1, compression=True, **kwargs)\n",
    "  compressor = Imgnet32yCompressor(trainer.analysis_transform, entropy_model)\n",
    "  decompressor = Imgnet32yDecompressor(entropy_model, trainer.synthesis_transform)\n",
    "  return compressor, decompressor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "92311c4a-2358-4f00-b031-409d9ae93d10",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - ETA: 0s - loss: 2247.7178 - distortion_loss: 0.9920 - rate_loss: 263.6259 - distortion_pass_through_loss: 0.9920 - rate_pass_through_loss: 263.6259"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:Computing quantization offsets using offset heuristic within a tf.function. Ideally, the offset heuristic should only be used to determine offsets once after training. Depending on the prior, estimating the offset might be computationally expensive.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 4s 4s/step - loss: 2247.7178 - distortion_loss: 0.9920 - rate_loss: 263.6259 - distortion_pass_through_loss: 0.9920 - rate_pass_through_loss: 263.6259 - val_loss: 2234.5063 - val_distortion_loss: 0.9865 - val_rate_loss: 261.4550 - val_distortion_pass_through_loss: 0.9865 - val_rate_pass_through_loss: 261.4550\n"
     ]
    }
   ],
   "source": [
    "trainer = train_imgnet32y_model(lmbda=2000)\n",
    "trainer.load_weights('imgnet32y_trainer.h5')\n",
    "compressor, decompressor = make_imgnet32y_codec(trainer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "e38259ad-42f4-4f8b-99b1-a083f8f5ab0c",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAACAAAAAgCAAAAABWESUoAAADPklEQVR4nAXBS09cZRgA4Pf2nXPmBswALddisSoVYtQQknrZ2F/gzrhw5b8y7ow7F8bERJddaDRGkwY0EcqlIBQGBmbOzLl+3/v6PLgpSfvFqweP9+ESinbkCimhxdnSVozwHVIgZuZKSpKxkmu0I7HFSTm12mYmRB+UiIlrKzgE75kiD4gMATNEEjEQYmYGMvFZDLHPO+IQk6YM74gpokiIiYUdUBsZmxZ6LiZkh/UrJQykgYSJpfbcSQTYMXfAsLwpuS1EOh2rEBIJGuVoPbZif62jM5KjsSCEgSNCQuJoxY81DCC36jyvoKdZMAAEIhIEQK6oXwQ0/9pmfTSoC/PIagSAigIAxhHnrRTZJeudYZG5CzPsBwZzIci5b3WnDdNW4knvpXL/FNKZCXMP0QIGpHQCPLc2vTj/tIWLq0ujh3MxFGi2zmZWK8t8lsx0Oc3YPnhmCbmoyZ2AYBbQAvtIcu0sxbFdFJy8//KPp42rI+mxSy9/f0KmoCJau2w1iuZSH9WX13vNi7q3HR2cnd1NgKwxbIqxjWB6RkZV6DcnY233lt2Iz8Cqchxr18ntdH3ceHdKZ8vhPeT9+QU/7OuLG7DDU0yUSZrtenDW8fMr7Yl21u0Xj313OAS03NAVZISxyWgU/CibXKUYrUI/PzgeIaBFLQICychLNazKLLtRp75zbfpgkfcvccpbiCIiuz47eONtnOJUVz7thqZNhRC1P1xyG4nLSjAJKUn30VWelMlgY/L3x6vD3/z4dPlJqiNp1hAEAlB3++Q4nj26nMtZdpbivavr/x7u/BWXimyCIZa9+J3u80H+ydG/3Ggkt83tst4cnbTN1QoSxSJv/fDRg/r5Y7f2c/OWroa6NZtf7Do1UwySMG6svdm/Ll5feNk6L6t0A8zizB1HIUF1QQhoaa3Ll19/Md04vxv1f43UBo82DqvYu9KMCRB6EkJj8cf+5FsIXsd5OdiC8ziEAKhAADAFqrbwLPsmbVV1YIXPlwe7oIiqQUXJMj05P4irr8bQEQu123lPf3IySaRkDGLKfx4XQpD8c19MDSH+0u1ORBtRAK2UzOxKg3a2lwugGx8w+Wy2+f0QLTYjiv3/RxvN0M3XYFUAAAAASUVORK5CYII=",
      "text/plain": [
       "<PIL.Image.Image image mode=L size=32x32>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "X_val = []\n",
    "for X,y in validation_dataset.take(5):\n",
    "    X_val.append(X)\n",
    "X_val = tf.stack(X_val)\n",
    "display_tf(X_val[2])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "da3cc99f-e3b5-4079-a9b3-ef6cf69acd8e",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAACAAAAAgCAAAAABWESUoAAAC80lEQVR4nAXBzXLjRBAA4O6enpEsOXbi2EuK2lBwW9gqeANel6fgxGkP3KCgqIKChI2X/NixJEuj6Zluvg/fgwcjKOBUHQCaKVYe64XXHDJ17KVoYsSsSY2cFzMaQ+utQrCShVlmLUguj0KGrJhTEX/Z7K7r2Mk5sWRRZ+jYEB2Q8xXNroxyc6PH/JoyixoC+FXsDQGYK6cZ0crF5cjOeWYk1AJUAZgHQ/K8KAkxFcsyzVSzz1qoKGBR4mTkwddYlRjFJjFzLMXMcs9pBiDNTEbeRONhM3TdGJlRHViRXrNZtb3ZnB5yVtPSjfPYJyxcF5IMTNk08Xff1x8OQxIFUys5STZ2lVtIxiouBMhzAixFER0vinO5GFMb2jrNfuQprNJTiIUIiYoRkqo55qXffi5HlW00mPqVKqFzBpLIExGxg3r9thrHwzzPj+PQkDPHqGWKYMkUuWai9crmN2U6Dk93Ja1W24v4z7/pHJJqQbYyHacN+Jbm9cPDf2rhzdfu7o94+oSHKNlxVjt8XNVuSQtrF6XX3Oz3v/6VhcJ5ziacNcT7zXWrLr6ca7PBno/3DzPbOY5FJ8eWCozDWgGGPV6nV0mlzOydVzRMpWJJiCmnonnMq9WpF/XLECaofNGSqiXnuYYJFpokLddZnOO23e76SVO2zI0yUqWyXOdTHIM/4xefjd1JJIems5RBMgcJevXum+7xJXF6en3/1fOPj6PUu8sximogJlJ/e1vnlQY93O+/fLv5eQ/17nY4PCvVRBxy016xaXXRkof+eI6bb5vdhfy077lB8GwGOM5zEXMhAP75g5y229306bfe16ziGJ3zrgtDl0P38dD/8iH6q9u/y90deRfIIZPLaI+9nJO9/H53IKqnJxywr4MGIk+8gKWjU5Q4D8+HsIhGzDYXWOY5gK+RwWk5Hdq5m+MIV3we4ArIhyRBAjqMLKGh+dzn2Vm1KAUahGIAGCCqkQfCplkGShbqYqEFXreCASUbLQNjffE/ewIQD5R+reYAAAAASUVORK5CYII=",
      "text/plain": [
       "<PIL.Image.Image image mode=L size=32x32>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "strings, entropies = compressor(X_example)\n",
    "reconstructions = decompressor(strings)\n",
    "display_tf(reconstructions[2])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "9a85f9f7-b5b2-4761-9bab-2fbe7619136f",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "String representation in hexadecimal: 0x42663f5aac295c10d78d281990de401383816c81bb02dbb74fb7112f99e67fc8\n",
      "Number of bits actually needed to represent it: 257.20\n"
     ]
    }
   ],
   "source": [
    "print(f\"String representation in hexadecimal: 0x{strings[2].numpy().hex()}\")\n",
    "print(f\"Number of bits actually needed to represent it: {entropies[2]:0.2f}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
