{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "id": "IqR2PQG4ZaZ0",
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-03-21 23:33:28.398690: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  AVX2 FMA\n",
      "To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2023-03-21 23:33:29.163000: W tensorflow/compiler/xla/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libnvinfer.so.7'; dlerror: libnvinfer.so.7: cannot open shared object file: No such file or directory\n",
      "2023-03-21 23:33:29.163058: W tensorflow/compiler/xla/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libnvinfer_plugin.so.7'; dlerror: libnvinfer_plugin.so.7: cannot open shared object file: No such file or directory\n",
      "2023-03-21 23:33:29.163065: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Cannot dlopen some TensorRT libraries. If you would like to use Nvidia GPU with TensorRT, please make sure the missing libraries mentioned above are installed properly.\n"
     ]
    }
   ],
   "source": [
    "from balle import *\n",
    "import matplotlib.pyplot as plt\n",
    "import tensorflow_decision_forests as tfdf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/15\n",
      "WARNING:tensorflow:From /home/server/.local/lib/python3.10/site-packages/tensorflow/python/autograph/pyct/static_analysis/liveness.py:83: Analyzer.lamba_check (from tensorflow.python.autograph.pyct.static_analysis.liveness) is deprecated and will be removed after 2023-09-23.\n",
      "Instructions for updating:\n",
      "Lambda fuctions will be no more assumed to be used in the statement where they are used, or at least in the same block. https://github.com/tensorflow/tensorflow/issues/56089\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From /home/server/.local/lib/python3.10/site-packages/tensorflow/python/autograph/pyct/static_analysis/liveness.py:83: Analyzer.lamba_check (from tensorflow.python.autograph.pyct.static_analysis.liveness) is deprecated and will be removed after 2023-09-23.\n",
      "Instructions for updating:\n",
      "Lambda fuctions will be no more assumed to be used in the statement where they are used, or at least in the same block. https://github.com/tensorflow/tensorflow/issues/56089\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "469/469 [==============================] - ETA: 0s - loss: 127.4174 - distortion_loss: 0.0697 - rate_loss: 92.5730 - distortion_pass_through_loss: 0.0697 - rate_pass_through_loss: 92.5666"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:Computing quantization offsets using offset heuristic within a tf.function. Ideally, the offset heuristic should only be used to determine offsets once after training. Depending on the prior, estimating the offset might be computationally expensive.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "469/469 [==============================] - 12s 12ms/step - loss: 127.4174 - distortion_loss: 0.0697 - rate_loss: 92.5730 - distortion_pass_through_loss: 0.0697 - rate_pass_through_loss: 92.5666 - val_loss: 107.8338 - val_distortion_loss: 0.0573 - val_rate_loss: 79.1746 - val_distortion_pass_through_loss: 0.0573 - val_rate_pass_through_loss: 79.1757\n",
      "Epoch 2/15\n",
      "469/469 [==============================] - 5s 11ms/step - loss: 97.3109 - distortion_loss: 0.0543 - rate_loss: 70.1758 - distortion_pass_through_loss: 0.0543 - rate_pass_through_loss: 70.1703 - val_loss: 85.7117 - val_distortion_loss: 0.0597 - val_rate_loss: 55.8391 - val_distortion_pass_through_loss: 0.0597 - val_rate_pass_through_loss: 55.8357\n",
      "Epoch 3/15\n",
      "469/469 [==============================] - 5s 10ms/step - loss: 81.2209 - distortion_loss: 0.0564 - rate_loss: 53.0393 - distortion_pass_through_loss: 0.0564 - rate_pass_through_loss: 53.0360 - val_loss: 71.1834 - val_distortion_loss: 0.0671 - val_rate_loss: 37.6260 - val_distortion_pass_through_loss: 0.0671 - val_rate_pass_through_loss: 37.6249\n",
      "Epoch 4/15\n",
      "469/469 [==============================] - 5s 11ms/step - loss: 71.5878 - distortion_loss: 0.0596 - rate_loss: 41.7882 - distortion_pass_through_loss: 0.0596 - rate_pass_through_loss: 41.7858 - val_loss: 62.7277 - val_distortion_loss: 0.0756 - val_rate_loss: 24.9348 - val_distortion_pass_through_loss: 0.0756 - val_rate_pass_through_loss: 24.9265\n",
      "Epoch 5/15\n",
      "469/469 [==============================] - 5s 11ms/step - loss: 65.9447 - distortion_loss: 0.0624 - rate_loss: 34.7677 - distortion_pass_through_loss: 0.0624 - rate_pass_through_loss: 34.7661 - val_loss: 57.6898 - val_distortion_loss: 0.0791 - val_rate_loss: 18.1353 - val_distortion_pass_through_loss: 0.0791 - val_rate_pass_through_loss: 18.1235\n",
      "Epoch 6/15\n",
      "469/469 [==============================] - 5s 11ms/step - loss: 62.4390 - distortion_loss: 0.0644 - rate_loss: 30.2232 - distortion_pass_through_loss: 0.0644 - rate_pass_through_loss: 30.2212 - val_loss: 54.4623 - val_distortion_loss: 0.0827 - val_rate_loss: 13.1245 - val_distortion_pass_through_loss: 0.0827 - val_rate_pass_through_loss: 13.1178\n",
      "Epoch 7/15\n",
      "469/469 [==============================] - 5s 11ms/step - loss: 59.8918 - distortion_loss: 0.0658 - rate_loss: 27.0163 - distortion_pass_through_loss: 0.0657 - rate_pass_through_loss: 27.0160 - val_loss: 51.2434 - val_distortion_loss: 0.0771 - val_rate_loss: 12.7051 - val_distortion_pass_through_loss: 0.0771 - val_rate_pass_through_loss: 12.7023\n",
      "Epoch 8/15\n",
      "469/469 [==============================] - 5s 11ms/step - loss: 57.7713 - distortion_loss: 0.0663 - rate_loss: 24.5977 - distortion_pass_through_loss: 0.0663 - rate_pass_through_loss: 24.5969 - val_loss: 49.9269 - val_distortion_loss: 0.0777 - val_rate_loss: 11.0519 - val_distortion_pass_through_loss: 0.0777 - val_rate_pass_through_loss: 11.0470\n",
      "Epoch 9/15\n",
      "469/469 [==============================] - 5s 11ms/step - loss: 55.8347 - distortion_loss: 0.0663 - rate_loss: 22.6796 - distortion_pass_through_loss: 0.0663 - rate_pass_through_loss: 22.6792 - val_loss: 48.1406 - val_distortion_loss: 0.0712 - val_rate_loss: 12.5462 - val_distortion_pass_through_loss: 0.0712 - val_rate_pass_through_loss: 12.5442\n",
      "Epoch 10/15\n",
      "469/469 [==============================] - 5s 11ms/step - loss: 53.8796 - distortion_loss: 0.0654 - rate_loss: 21.1932 - distortion_pass_through_loss: 0.0654 - rate_pass_through_loss: 21.1926 - val_loss: 47.1776 - val_distortion_loss: 0.0692 - val_rate_loss: 12.5927 - val_distortion_pass_through_loss: 0.0692 - val_rate_pass_through_loss: 12.5894\n",
      "Epoch 11/15\n",
      "469/469 [==============================] - 5s 11ms/step - loss: 52.2017 - distortion_loss: 0.0643 - rate_loss: 20.0288 - distortion_pass_through_loss: 0.0643 - rate_pass_through_loss: 20.0279 - val_loss: 46.3186 - val_distortion_loss: 0.0655 - val_rate_loss: 13.5673 - val_distortion_pass_through_loss: 0.0655 - val_rate_pass_through_loss: 13.5639\n",
      "Epoch 12/15\n",
      "469/469 [==============================] - 5s 11ms/step - loss: 50.7922 - distortion_loss: 0.0632 - rate_loss: 19.1860 - distortion_pass_through_loss: 0.0632 - rate_pass_through_loss: 19.1856 - val_loss: 45.8695 - val_distortion_loss: 0.0637 - val_rate_loss: 14.0300 - val_distortion_pass_through_loss: 0.0637 - val_rate_pass_through_loss: 14.0291\n",
      "Epoch 13/15\n",
      "469/469 [==============================] - 5s 11ms/step - loss: 49.6255 - distortion_loss: 0.0622 - rate_loss: 18.5210 - distortion_pass_through_loss: 0.0622 - rate_pass_through_loss: 18.5204 - val_loss: 45.5351 - val_distortion_loss: 0.0630 - val_rate_loss: 14.0181 - val_distortion_pass_through_loss: 0.0631 - val_rate_pass_through_loss: 14.0138\n",
      "Epoch 14/15\n",
      "469/469 [==============================] - 5s 11ms/step - loss: 48.7643 - distortion_loss: 0.0616 - rate_loss: 17.9672 - distortion_pass_through_loss: 0.0616 - rate_pass_through_loss: 17.9667 - val_loss: 45.2923 - val_distortion_loss: 0.0624 - val_rate_loss: 14.0686 - val_distortion_pass_through_loss: 0.0625 - val_rate_pass_through_loss: 14.0643\n",
      "Epoch 15/15\n",
      "469/469 [==============================] - 5s 10ms/step - loss: 48.0715 - distortion_loss: 0.0611 - rate_loss: 17.5293 - distortion_pass_through_loss: 0.0611 - rate_pass_through_loss: 17.5290 - val_loss: 45.1048 - val_distortion_loss: 0.0618 - val_rate_loss: 14.2225 - val_distortion_pass_through_loss: 0.0618 - val_rate_pass_through_loss: 14.2232\n"
     ]
    }
   ],
   "source": [
    "trainer = train_mnist_model(lmbda=500)\n",
    "compressor, decompressor = make_mnist_codec(trainer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_latent(x,y):\n",
    "    x = tf.cast(tf.expand_dims(x,axis=0),tf.float32) / 255.\n",
    "    z = tf.round(compressor.analysis_transform(x)[0])\n",
    "    z = tf.cast(z, tf.int8)\n",
    "    return z,y\n",
    "\n",
    "training_dataset2 = training_dataset.map(get_latent).batch(100)\n",
    "validation_dataset2 = validation_dataset.map(get_latent).batch(100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Use 12 thread(s) for training\n",
      "Use /tmp/tmpfdh6a3_0 as temporary training directory\n",
      "Reading training dataset...\n",
      "Training tensor examples:\n",
      "Features: Tensor(\"data:0\", shape=(None, 50), dtype=int8)\n",
      "Label: Tensor(\"data_1:0\", shape=(None,), dtype=int64)\n",
      "Weights: None\n",
      "Normalized tensor features:\n",
      " {'data:0.0': SemanticTensor(semantic=<Semantic.NUMERICAL: 1>, tensor=<tf.Tensor 'strided_slice:0' shape=(None,) dtype=float32>), 'data:0.1': SemanticTensor(semantic=<Semantic.NUMERICAL: 1>, tensor=<tf.Tensor 'strided_slice_1:0' shape=(None,) dtype=float32>), 'data:0.2': SemanticTensor(semantic=<Semantic.NUMERICAL: 1>, tensor=<tf.Tensor 'strided_slice_2:0' shape=(None,) dtype=float32>), 'data:0.3': SemanticTensor(semantic=<Semantic.NUMERICAL: 1>, tensor=<tf.Tensor 'strided_slice_3:0' shape=(None,) dtype=float32>), 'data:0.4': SemanticTensor(semantic=<Semantic.NUMERICAL: 1>, tensor=<tf.Tensor 'strided_slice_4:0' shape=(None,) dtype=float32>), 'data:0.5': SemanticTensor(semantic=<Semantic.NUMERICAL: 1>, tensor=<tf.Tensor 'strided_slice_5:0' shape=(None,) dtype=float32>), 'data:0.6': SemanticTensor(semantic=<Semantic.NUMERICAL: 1>, tensor=<tf.Tensor 'strided_slice_6:0' shape=(None,) dtype=float32>), 'data:0.7': SemanticTensor(semantic=<Semantic.NUMERICAL: 1>, tensor=<tf.Tensor 'strided_slice_7:0' shape=(None,) dtype=float32>), 'data:0.8': SemanticTensor(semantic=<Semantic.NUMERICAL: 1>, tensor=<tf.Tensor 'strided_slice_8:0' shape=(None,) dtype=float32>), 'data:0.9': SemanticTensor(semantic=<Semantic.NUMERICAL: 1>, tensor=<tf.Tensor 'strided_slice_9:0' shape=(None,) dtype=float32>), 'data:0.10': SemanticTensor(semantic=<Semantic.NUMERICAL: 1>, tensor=<tf.Tensor 'strided_slice_10:0' shape=(None,) dtype=float32>), 'data:0.11': SemanticTensor(semantic=<Semantic.NUMERICAL: 1>, tensor=<tf.Tensor 'strided_slice_11:0' shape=(None,) dtype=float32>), 'data:0.12': SemanticTensor(semantic=<Semantic.NUMERICAL: 1>, tensor=<tf.Tensor 'strided_slice_12:0' shape=(None,) dtype=float32>), 'data:0.13': SemanticTensor(semantic=<Semantic.NUMERICAL: 1>, tensor=<tf.Tensor 'strided_slice_13:0' shape=(None,) dtype=float32>), 'data:0.14': SemanticTensor(semantic=<Semantic.NUMERICAL: 1>, tensor=<tf.Tensor 'strided_slice_14:0' shape=(None,) dtype=float32>), 'data:0.15': SemanticTensor(semantic=<Semantic.NUMERICAL: 1>, tensor=<tf.Tensor 'strided_slice_15:0' shape=(None,) dtype=float32>), 'data:0.16': SemanticTensor(semantic=<Semantic.NUMERICAL: 1>, tensor=<tf.Tensor 'strided_slice_16:0' shape=(None,) dtype=float32>), 'data:0.17': SemanticTensor(semantic=<Semantic.NUMERICAL: 1>, tensor=<tf.Tensor 'strided_slice_17:0' shape=(None,) dtype=float32>), 'data:0.18': SemanticTensor(semantic=<Semantic.NUMERICAL: 1>, tensor=<tf.Tensor 'strided_slice_18:0' shape=(None,) dtype=float32>), 'data:0.19': SemanticTensor(semantic=<Semantic.NUMERICAL: 1>, tensor=<tf.Tensor 'strided_slice_19:0' shape=(None,) dtype=float32>), 'data:0.20': SemanticTensor(semantic=<Semantic.NUMERICAL: 1>, tensor=<tf.Tensor 'strided_slice_20:0' shape=(None,) dtype=float32>), 'data:0.21': SemanticTensor(semantic=<Semantic.NUMERICAL: 1>, tensor=<tf.Tensor 'strided_slice_21:0' shape=(None,) dtype=float32>), 'data:0.22': SemanticTensor(semantic=<Semantic.NUMERICAL: 1>, tensor=<tf.Tensor 'strided_slice_22:0' shape=(None,) dtype=float32>), 'data:0.23': SemanticTensor(semantic=<Semantic.NUMERICAL: 1>, tensor=<tf.Tensor 'strided_slice_23:0' shape=(None,) dtype=float32>), 'data:0.24': SemanticTensor(semantic=<Semantic.NUMERICAL: 1>, tensor=<tf.Tensor 'strided_slice_24:0' shape=(None,) dtype=float32>), 'data:0.25': SemanticTensor(semantic=<Semantic.NUMERICAL: 1>, tensor=<tf.Tensor 'strided_slice_25:0' shape=(None,) dtype=float32>), 'data:0.26': SemanticTensor(semantic=<Semantic.NUMERICAL: 1>, tensor=<tf.Tensor 'strided_slice_26:0' shape=(None,) dtype=float32>), 'data:0.27': SemanticTensor(semantic=<Semantic.NUMERICAL: 1>, tensor=<tf.Tensor 'strided_slice_27:0' shape=(None,) dtype=float32>), 'data:0.28': SemanticTensor(semantic=<Semantic.NUMERICAL: 1>, tensor=<tf.Tensor 'strided_slice_28:0' shape=(None,) dtype=float32>), 'data:0.29': SemanticTensor(semantic=<Semantic.NUMERICAL: 1>, tensor=<tf.Tensor 'strided_slice_29:0' shape=(None,) dtype=float32>), 'data:0.30': SemanticTensor(semantic=<Semantic.NUMERICAL: 1>, tensor=<tf.Tensor 'strided_slice_30:0' shape=(None,) dtype=float32>), 'data:0.31': SemanticTensor(semantic=<Semantic.NUMERICAL: 1>, tensor=<tf.Tensor 'strided_slice_31:0' shape=(None,) dtype=float32>), 'data:0.32': SemanticTensor(semantic=<Semantic.NUMERICAL: 1>, tensor=<tf.Tensor 'strided_slice_32:0' shape=(None,) dtype=float32>), 'data:0.33': SemanticTensor(semantic=<Semantic.NUMERICAL: 1>, tensor=<tf.Tensor 'strided_slice_33:0' shape=(None,) dtype=float32>), 'data:0.34': SemanticTensor(semantic=<Semantic.NUMERICAL: 1>, tensor=<tf.Tensor 'strided_slice_34:0' shape=(None,) dtype=float32>), 'data:0.35': SemanticTensor(semantic=<Semantic.NUMERICAL: 1>, tensor=<tf.Tensor 'strided_slice_35:0' shape=(None,) dtype=float32>), 'data:0.36': SemanticTensor(semantic=<Semantic.NUMERICAL: 1>, tensor=<tf.Tensor 'strided_slice_36:0' shape=(None,) dtype=float32>), 'data:0.37': SemanticTensor(semantic=<Semantic.NUMERICAL: 1>, tensor=<tf.Tensor 'strided_slice_37:0' shape=(None,) dtype=float32>), 'data:0.38': SemanticTensor(semantic=<Semantic.NUMERICAL: 1>, tensor=<tf.Tensor 'strided_slice_38:0' shape=(None,) dtype=float32>), 'data:0.39': SemanticTensor(semantic=<Semantic.NUMERICAL: 1>, tensor=<tf.Tensor 'strided_slice_39:0' shape=(None,) dtype=float32>), 'data:0.40': SemanticTensor(semantic=<Semantic.NUMERICAL: 1>, tensor=<tf.Tensor 'strided_slice_40:0' shape=(None,) dtype=float32>), 'data:0.41': SemanticTensor(semantic=<Semantic.NUMERICAL: 1>, tensor=<tf.Tensor 'strided_slice_41:0' shape=(None,) dtype=float32>), 'data:0.42': SemanticTensor(semantic=<Semantic.NUMERICAL: 1>, tensor=<tf.Tensor 'strided_slice_42:0' shape=(None,) dtype=float32>), 'data:0.43': SemanticTensor(semantic=<Semantic.NUMERICAL: 1>, tensor=<tf.Tensor 'strided_slice_43:0' shape=(None,) dtype=float32>), 'data:0.44': SemanticTensor(semantic=<Semantic.NUMERICAL: 1>, tensor=<tf.Tensor 'strided_slice_44:0' shape=(None,) dtype=float32>), 'data:0.45': SemanticTensor(semantic=<Semantic.NUMERICAL: 1>, tensor=<tf.Tensor 'strided_slice_45:0' shape=(None,) dtype=float32>), 'data:0.46': SemanticTensor(semantic=<Semantic.NUMERICAL: 1>, tensor=<tf.Tensor 'strided_slice_46:0' shape=(None,) dtype=float32>), 'data:0.47': SemanticTensor(semantic=<Semantic.NUMERICAL: 1>, tensor=<tf.Tensor 'strided_slice_47:0' shape=(None,) dtype=float32>), 'data:0.48': SemanticTensor(semantic=<Semantic.NUMERICAL: 1>, tensor=<tf.Tensor 'strided_slice_48:0' shape=(None,) dtype=float32>), 'data:0.49': SemanticTensor(semantic=<Semantic.NUMERICAL: 1>, tensor=<tf.Tensor 'strided_slice_49:0' shape=(None,) dtype=float32>)}\n",
      "Training dataset read in 0:01:48.712055. Found 60000 examples.\n",
      "Training model...\n",
      "Standard output detected as not visible to the user e.g. running in a notebook. Creating a training log redirection. If training gets stuck, try calling tfdf.keras.set_training_logs_redirection(False).\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[INFO 2023-03-21T23:36:43.649780178-05:00 kernel.cc:756] Start Yggdrasil model training\n",
      "[INFO 2023-03-21T23:36:43.650526687-05:00 kernel.cc:757] Collect training examples\n",
      "[INFO 2023-03-21T23:36:43.650893799-05:00 kernel.cc:388] Number of batches: 600\n",
      "[INFO 2023-03-21T23:36:43.650909699-05:00 kernel.cc:389] Number of examples: 60000\n",
      "[INFO 2023-03-21T23:36:43.698941353-05:00 kernel.cc:774] Training dataset:\n",
      "Number of records: 60000\n",
      "Number of columns: 51\n",
      "\n",
      "Number of columns by type:\n",
      "\tNUMERICAL: 50 (98.0392%)\n",
      "\tCATEGORICAL: 1 (1.96078%)\n",
      "\n",
      "Columns:\n",
      "\n",
      "NUMERICAL: 50 (98.0392%)\n",
      "\t1: \"data:0.0\" NUMERICAL mean:0 min:0 max:0 sd:0\n",
      "\t2: \"data:0.1\" NUMERICAL mean:0 min:0 max:0 sd:0\n",
      "\t3: \"data:0.10\" NUMERICAL mean:0 min:0 max:0 sd:0\n",
      "\t4: \"data:0.11\" NUMERICAL mean:0 min:0 max:0 sd:0\n",
      "\t5: \"data:0.12\" NUMERICAL mean:0.00528333 min:-1 max:2 sd:0.398316\n",
      "\t6: \"data:0.13\" NUMERICAL mean:0.0183333 min:-1 max:1 sd:0.33451\n",
      "\t7: \"data:0.14\" NUMERICAL mean:0 min:0 max:0 sd:0\n",
      "\t8: \"data:0.15\" NUMERICAL mean:-0.00428333 min:-2 max:3 sd:0.647327\n",
      "\t9: \"data:0.16\" NUMERICAL mean:0 min:0 max:0 sd:0\n",
      "\t10: \"data:0.17\" NUMERICAL mean:0 min:0 max:0 sd:0\n",
      "\t11: \"data:0.18\" NUMERICAL mean:0 min:0 max:0 sd:0\n",
      "\t12: \"data:0.19\" NUMERICAL mean:0 min:0 max:0 sd:0\n",
      "\t13: \"data:0.2\" NUMERICAL mean:0 min:0 max:0 sd:0\n",
      "\t14: \"data:0.20\" NUMERICAL mean:0 min:0 max:0 sd:0\n",
      "\t15: \"data:0.21\" NUMERICAL mean:-0.0035 min:-1 max:1 sd:0.329779\n",
      "\t16: \"data:0.22\" NUMERICAL mean:0 min:0 max:0 sd:0\n",
      "\t17: \"data:0.23\" NUMERICAL mean:0 min:0 max:0 sd:0\n",
      "\t18: \"data:0.24\" NUMERICAL mean:0 min:0 max:0 sd:0\n",
      "\t19: \"data:0.25\" NUMERICAL mean:0 min:0 max:0 sd:0\n",
      "\t20: \"data:0.26\" NUMERICAL mean:0 min:0 max:0 sd:0\n",
      "\t21: \"data:0.27\" NUMERICAL mean:0.0235833 min:-3 max:3 sd:1.01425\n",
      "\t22: \"data:0.28\" NUMERICAL mean:0.00851667 min:-3 max:4 sd:1.10712\n",
      "\t23: \"data:0.29\" NUMERICAL mean:0 min:0 max:0 sd:0\n",
      "\t24: \"data:0.3\" NUMERICAL mean:0 min:0 max:0 sd:0\n",
      "\t25: \"data:0.30\" NUMERICAL mean:0.00418333 min:-1 max:1 sd:0.0718737\n",
      "\t26: \"data:0.31\" NUMERICAL mean:0 min:0 max:0 sd:0\n",
      "\t27: \"data:0.32\" NUMERICAL mean:0 min:0 max:0 sd:0\n",
      "\t28: \"data:0.33\" NUMERICAL mean:0 min:0 max:0 sd:0\n",
      "\t29: \"data:0.34\" NUMERICAL mean:0 min:0 max:0 sd:0\n",
      "\t30: \"data:0.35\" NUMERICAL mean:0 min:0 max:0 sd:0\n",
      "\t31: \"data:0.36\" NUMERICAL mean:0 min:0 max:0 sd:0\n",
      "\t32: \"data:0.37\" NUMERICAL mean:0 min:0 max:0 sd:0\n",
      "\t33: \"data:0.38\" NUMERICAL mean:0 min:0 max:0 sd:0\n",
      "\t34: \"data:0.39\" NUMERICAL mean:0.00298333 min:-3 max:3 sd:0.947263\n",
      "\t35: \"data:0.4\" NUMERICAL mean:0 min:0 max:0 sd:0\n",
      "\t36: \"data:0.40\" NUMERICAL mean:0 min:0 max:0 sd:0\n",
      "\t37: \"data:0.41\" NUMERICAL mean:0 min:0 max:0 sd:0\n",
      "\t38: \"data:0.42\" NUMERICAL mean:0 min:0 max:0 sd:0\n",
      "\t39: \"data:0.43\" NUMERICAL mean:0 min:0 max:0 sd:0\n",
      "\t40: \"data:0.44\" NUMERICAL mean:0 min:0 max:0 sd:0\n",
      "\t41: \"data:0.45\" NUMERICAL mean:0 min:0 max:0 sd:0\n",
      "\t42: \"data:0.46\" NUMERICAL mean:0 min:0 max:0 sd:0\n",
      "\t43: \"data:0.47\" NUMERICAL mean:0 min:0 max:0 sd:0\n",
      "\t44: \"data:0.48\" NUMERICAL mean:0 min:0 max:0 sd:0\n",
      "\t45: \"data:0.49\" NUMERICAL mean:0.01845 min:-2 max:2 sd:0.593978\n",
      "\t46: \"data:0.5\" NUMERICAL mean:0 min:0 max:0 sd:0\n",
      "\t47: \"data:0.6\" NUMERICAL mean:0.00425 min:-3 max:3 sd:0.775456\n",
      "\t48: \"data:0.7\" NUMERICAL mean:0 min:0 max:0 sd:0\n",
      "\t49: \"data:0.8\" NUMERICAL mean:-0.0504667 min:-3 max:2 sd:0.673736\n",
      "\t50: \"data:0.9\" NUMERICAL mean:0 min:0 max:0 sd:0\n",
      "\n",
      "CATEGORICAL: 1 (1.96078%)\n",
      "\t0: \"__LABEL\" CATEGORICAL integerized vocab-size:11 no-ood-item\n",
      "\n",
      "Terminology:\n",
      "\tnas: Number of non-available (i.e. missing) values.\n",
      "\tood: Out of dictionary.\n",
      "\tmanually-defined: Attribute which type is manually defined by the user i.e. the type was not automatically inferred.\n",
      "\ttokenized: The attribute value is obtained through tokenization.\n",
      "\thas-dict: The attribute is attached to a string dictionary e.g. a categorical attribute stored as a string.\n",
      "\tvocab-size: Number of unique values.\n",
      "\n",
      "[INFO 2023-03-21T23:36:43.699720483-05:00 kernel.cc:790] Configure learner\n",
      "[INFO 2023-03-21T23:36:43.700528557-05:00 kernel.cc:804] Training config:\n",
      "learner: \"RANDOM_FOREST\"\n",
      "features: \"^data:0\\\\.0$\"\n",
      "features: \"^data:0\\\\.1$\"\n",
      "features: \"^data:0\\\\.10$\"\n",
      "features: \"^data:0\\\\.11$\"\n",
      "features: \"^data:0\\\\.12$\"\n",
      "features: \"^data:0\\\\.13$\"\n",
      "features: \"^data:0\\\\.14$\"\n",
      "features: \"^data:0\\\\.15$\"\n",
      "features: \"^data:0\\\\.16$\"\n",
      "features: \"^data:0\\\\.17$\"\n",
      "features: \"^data:0\\\\.18$\"\n",
      "features: \"^data:0\\\\.19$\"\n",
      "features: \"^data:0\\\\.2$\"\n",
      "features: \"^data:0\\\\.20$\"\n",
      "features: \"^data:0\\\\.21$\"\n",
      "features: \"^data:0\\\\.22$\"\n",
      "features: \"^data:0\\\\.23$\"\n",
      "features: \"^data:0\\\\.24$\"\n",
      "features: \"^data:0\\\\.25$\"\n",
      "features: \"^data:0\\\\.26$\"\n",
      "features: \"^data:0\\\\.27$\"\n",
      "features: \"^data:0\\\\.28$\"\n",
      "features: \"^data:0\\\\.29$\"\n",
      "features: \"^data:0\\\\.3$\"\n",
      "features: \"^data:0\\\\.30$\"\n",
      "features: \"^data:0\\\\.31$\"\n",
      "features: \"^data:0\\\\.32$\"\n",
      "features: \"^data:0\\\\.33$\"\n",
      "features: \"^data:0\\\\.34$\"\n",
      "features: \"^data:0\\\\.35$\"\n",
      "features: \"^data:0\\\\.36$\"\n",
      "features: \"^data:0\\\\.37$\"\n",
      "features: \"^data:0\\\\.38$\"\n",
      "features: \"^data:0\\\\.39$\"\n",
      "features: \"^data:0\\\\.4$\"\n",
      "features: \"^data:0\\\\.40$\"\n",
      "features: \"^data:0\\\\.41$\"\n",
      "features: \"^data:0\\\\.42$\"\n",
      "features: \"^data:0\\\\.43$\"\n",
      "features: \"^data:0\\\\.44$\"\n",
      "features: \"^data:0\\\\.45$\"\n",
      "features: \"^data:0\\\\.46$\"\n",
      "features: \"^data:0\\\\.47$\"\n",
      "features: \"^data:0\\\\.48$\"\n",
      "features: \"^data:0\\\\.49$\"\n",
      "features: \"^data:0\\\\.5$\"\n",
      "features: \"^data:0\\\\.6$\"\n",
      "features: \"^data:0\\\\.7$\"\n",
      "features: \"^data:0\\\\.8$\"\n",
      "features: \"^data:0\\\\.9$\"\n",
      "label: \"^__LABEL$\"\n",
      "task: CLASSIFICATION\n",
      "random_seed: 123456\n",
      "metadata {\n",
      "  framework: \"TF Keras\"\n",
      "}\n",
      "pure_serving_model: false\n",
      "[yggdrasil_decision_forests.model.random_forest.proto.random_forest_config] {\n",
      "  num_trees: 300\n",
      "  decision_tree {\n",
      "    max_depth: 16\n",
      "    min_examples: 5\n",
      "    in_split_min_examples_check: true\n",
      "    keep_non_leaf_label_distribution: true\n",
      "    num_candidate_attributes: 0\n",
      "    missing_value_policy: GLOBAL_IMPUTATION\n",
      "    allow_na_conditions: false\n",
      "    categorical_set_greedy_forward {\n",
      "      sampling: 0.1\n",
      "      max_num_items: -1\n",
      "      min_item_frequency: 1\n",
      "    }\n",
      "    growing_strategy_local {\n",
      "    }\n",
      "    categorical {\n",
      "      cart {\n",
      "      }\n",
      "    }\n",
      "    axis_aligned_split {\n",
      "    }\n",
      "    internal {\n",
      "      sorting_strategy: PRESORTED\n",
      "    }\n",
      "    uplift {\n",
      "      min_examples_in_treatment: 5\n",
      "      split_score: KULLBACK_LEIBLER\n",
      "    }\n",
      "  }\n",
      "  winner_take_all_inference: true\n",
      "  compute_oob_performances: true\n",
      "  compute_oob_variable_importances: false\n",
      "  num_oob_variable_importances_permutations: 1\n",
      "  bootstrap_training_dataset: true\n",
      "  bootstrap_size_ratio: 1\n",
      "  adapt_bootstrap_size_ratio_for_maximum_training_duration: false\n",
      "  sampling_with_replacement: true\n",
      "}\n",
      "\n",
      "[INFO 2023-03-21T23:36:43.701207138-05:00 kernel.cc:807] Deployment config:\n",
      "cache_path: \"/tmp/tmpfdh6a3_0/working_cache\"\n",
      "num_threads: 12\n",
      "try_resume_training: true\n",
      "\n",
      "[INFO 2023-03-21T23:36:43.701477548-05:00 kernel.cc:868] Train model\n",
      "[INFO 2023-03-21T23:36:43.702423893-05:00 random_forest.cc:415] Training random forest on 60000 example(s) and 50 feature(s).\n",
      "[INFO 2023-03-21T23:36:44.469274138-05:00 random_forest.cc:804] Training of tree  1/300 (tree index:1) done accuracy:0.826701 logloss:6.24633\n",
      "[INFO 2023-03-21T23:36:44.59716667-05:00 random_forest.cc:804] Training of tree  11/300 (tree index:10) done accuracy:0.833507 logloss:4.38176\n",
      "[INFO 2023-03-21T23:36:45.331614651-05:00 random_forest.cc:804] Training of tree  21/300 (tree index:20) done accuracy:0.837453 logloss:3.69784\n",
      "[INFO 2023-03-21T23:36:46.035581466-05:00 random_forest.cc:804] Training of tree  31/300 (tree index:30) done accuracy:0.838233 logloss:3.37894\n",
      "[INFO 2023-03-21T23:36:46.739115224-05:00 random_forest.cc:804] Training of tree  41/300 (tree index:39) done accuracy:0.83905 logloss:3.20252\n",
      "[INFO 2023-03-21T23:36:47.445508236-05:00 random_forest.cc:804] Training of tree  51/300 (tree index:50) done accuracy:0.839867 logloss:3.07035\n",
      "[INFO 2023-03-21T23:36:48.09547592-05:00 random_forest.cc:804] Training of tree  61/300 (tree index:60) done accuracy:0.840117 logloss:2.982\n",
      "[INFO 2023-03-21T23:36:48.320687455-05:00 random_forest.cc:804] Training of tree  71/300 (tree index:71) done accuracy:0.840567 logloss:2.90611\n",
      "[INFO 2023-03-21T23:36:49.014008002-05:00 random_forest.cc:804] Training of tree  81/300 (tree index:81) done accuracy:0.84075 logloss:2.85094\n",
      "[INFO 2023-03-21T23:36:49.718419941-05:00 random_forest.cc:804] Training of tree  91/300 (tree index:91) done accuracy:0.84055 logloss:2.79665\n",
      "[INFO 2023-03-21T23:36:50.425084079-05:00 random_forest.cc:804] Training of tree  101/300 (tree index:100) done accuracy:0.840683 logloss:2.745\n",
      "[INFO 2023-03-21T23:36:51.10318474-05:00 random_forest.cc:804] Training of tree  111/300 (tree index:110) done accuracy:0.840533 logloss:2.70436\n",
      "[INFO 2023-03-21T23:36:51.734142368-05:00 random_forest.cc:804] Training of tree  121/300 (tree index:120) done accuracy:0.8405 logloss:2.6696\n",
      "[INFO 2023-03-21T23:36:52.011993159-05:00 random_forest.cc:804] Training of tree  131/300 (tree index:130) done accuracy:0.840683 logloss:2.63484\n",
      "[INFO 2023-03-21T23:36:52.729578755-05:00 random_forest.cc:804] Training of tree  141/300 (tree index:139) done accuracy:0.840717 logloss:2.60275\n",
      "[INFO 2023-03-21T23:36:53.40875833-05:00 random_forest.cc:804] Training of tree  151/300 (tree index:150) done accuracy:0.84055 logloss:2.57531\n",
      "[INFO 2023-03-21T23:36:54.064266264-05:00 random_forest.cc:804] Training of tree  161/300 (tree index:160) done accuracy:0.84055 logloss:2.55038\n",
      "[INFO 2023-03-21T23:36:54.754162756-05:00 random_forest.cc:804] Training of tree  171/300 (tree index:170) done accuracy:0.840783 logloss:2.52141\n",
      "[INFO 2023-03-21T23:36:55.380000174-05:00 random_forest.cc:804] Training of tree  181/300 (tree index:180) done accuracy:0.840983 logloss:2.50129\n",
      "[INFO 2023-03-21T23:36:55.784493007-05:00 random_forest.cc:804] Training of tree  191/300 (tree index:190) done accuracy:0.841033 logloss:2.48372\n",
      "[INFO 2023-03-21T23:36:56.412157683-05:00 random_forest.cc:804] Training of tree  201/300 (tree index:200) done accuracy:0.84115 logloss:2.47102\n",
      "[INFO 2023-03-21T23:36:57.098371294-05:00 random_forest.cc:804] Training of tree  211/300 (tree index:210) done accuracy:0.84105 logloss:2.4511\n",
      "[INFO 2023-03-21T23:36:57.797857565-05:00 random_forest.cc:804] Training of tree  221/300 (tree index:220) done accuracy:0.8411 logloss:2.43989\n",
      "[INFO 2023-03-21T23:36:58.420216435-05:00 random_forest.cc:804] Training of tree  231/300 (tree index:230) done accuracy:0.8412 logloss:2.42462\n",
      "[INFO 2023-03-21T23:36:59.069194434-05:00 random_forest.cc:804] Training of tree  241/300 (tree index:240) done accuracy:0.841183 logloss:2.41453\n",
      "[INFO 2023-03-21T23:36:59.434474262-05:00 random_forest.cc:804] Training of tree  251/300 (tree index:250) done accuracy:0.841217 logloss:2.40314\n",
      "[INFO 2023-03-21T23:37:00.10353337-05:00 random_forest.cc:804] Training of tree  261/300 (tree index:260) done accuracy:0.841267 logloss:2.39728\n",
      "[INFO 2023-03-21T23:37:00.788127632-05:00 random_forest.cc:804] Training of tree  271/300 (tree index:270) done accuracy:0.841267 logloss:2.38726\n",
      "[INFO 2023-03-21T23:37:01.458697356-05:00 random_forest.cc:804] Training of tree  281/300 (tree index:280) done accuracy:0.84135 logloss:2.37838\n",
      "[INFO 2023-03-21T23:37:02.03828178-05:00 random_forest.cc:804] Training of tree  291/300 (tree index:290) done accuracy:0.841233 logloss:2.37116\n",
      "[INFO 2023-03-21T23:37:02.326683901-05:00 random_forest.cc:804] Training of tree  300/300 (tree index:299) done accuracy:0.841267 logloss:2.35958\n",
      "[INFO 2023-03-21T23:37:02.326893276-05:00 random_forest.cc:884] Final OOB metrics: accuracy:0.841267 logloss:2.35958\n",
      "[INFO 2023-03-21T23:37:02.801282044-05:00 kernel.cc:905] Export model in log directory: /tmp/tmpfdh6a3_0 with prefix 8570f8a883f84c68\n",
      "[INFO 2023-03-21T23:37:03.693125191-05:00 kernel.cc:923] Save model in resources\n",
      "[INFO 2023-03-21T23:37:03.696975625-05:00 abstract_model.cc:849] Model self evaluation:\n",
      "Number of predictions (without weights): 60000\n",
      "Number of predictions (with weights): 60000\n",
      "Task: CLASSIFICATION\n",
      "Label: __LABEL\n",
      "\n",
      "Accuracy: 0.841267  CI95[W][0.838792 0.843717]\n",
      "LogLoss: : 2.35958\n",
      "ErrorRate: : 0.158733\n",
      "\n",
      "Default Accuracy: : 0.112367\n",
      "Default LogLoss: : 2.30116\n",
      "Default ErrorRate: : 0.887633\n",
      "\n",
      "Confusion Table:\n",
      "truth\\prediction\n",
      "    0     1     2     3     4     5     6     7     8     9    10\n",
      " 0  0     0     0     0     0     0     0     0     0     0     0\n",
      " 1  0  5427     8    91    20    13   146   110    14    61    33\n",
      " 2  0     2  6482    64    15    12    18    39    24    68    18\n",
      " 3  0   115    88  4969   168    39    66   117    78   274    44\n",
      " 4  0    47    54   221  4950     7   269    42    73   401    67\n",
      " 5  0    13    81    43     3  4588    27   140   161    32   754\n",
      " 6  0   107    27    73   288     6  4434   149    47   179   111\n",
      " 7  0   104    50    39    18    53   152  5462     6    29     5\n",
      " 8  0    30   150    88    51    71    48     6  5233    35   553\n",
      " 9  0    47   106   162   286    40   318    77    37  4597   181\n",
      "10  0    58    84    50    89   505    89    13   560   167  4334\n",
      "Total: 60000\n",
      "\n",
      "One vs other classes:\n",
      "\n",
      "[INFO 2023-03-21T23:37:04.047631371-05:00 kernel.cc:1214] Loading model from path /tmp/tmpfdh6a3_0/model/ with prefix 8570f8a883f84c68\n",
      "[INFO 2023-03-21T23:37:06.442746141-05:00 decision_forest.cc:661] Model loaded with 300 root(s), 1166146 node(s), and 11 input feature(s).\n",
      "[INFO 2023-03-21T23:37:06.442777249-05:00 abstract_model.cc:1311] Engine \"RandomForestGeneric\" built\n",
      "[INFO 2023-03-21T23:37:06.442803218-05:00 kernel.cc:1046] Use fast generic engine\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model trained in 0:00:22.986745\n",
      "Compiling model...\n",
      "WARNING:tensorflow:AutoGraph could not transform <function simple_ml_inference_op_with_handle at 0x7f307cdde200> and will run it as-is.\n",
      "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
      "Cause: could not get source code\n",
      "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:AutoGraph could not transform <function simple_ml_inference_op_with_handle at 0x7f307cdde200> and will run it as-is.\n",
      "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
      "Cause: could not get source code\n",
      "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING: AutoGraph could not transform <function simple_ml_inference_op_with_handle at 0x7f307cdde200> and will run it as-is.\n",
      "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
      "Cause: could not get source code\n",
      "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n",
      "Model compiled.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x7f306c0eee30>"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model = tfdf.keras.RandomForestModel(verbose=2)\n",
    "model.fit(training_dataset2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "100/100 [==============================] - 18s 176ms/step - loss: 0.0000e+00 - accuracy: 0.8428\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[0.0, 0.8428000211715698]"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.compile(metrics=[\"accuracy\"])\n",
    "model.evaluate(validation_dataset2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "html = tfdf.model_plotter.plot_model(model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "\n",
       "<script src=\"https://d3js.org/d3.v6.min.js\"></script>\n",
       "<div id=\"tree_plot_83f506b8bfe04b3f9caa3f506ee25869\"></div>\n",
       "<script>\n",
       "/*\n",
       " * Copyright 2021 Google LLC.\n",
       " * Licensed under the Apache License, Version 2.0 (the \"License\");\n",
       " * you may not use this file except in compliance with the License.\n",
       " * You may obtain a copy of the License at\n",
       " *\n",
       " *     https://www.apache.org/licenses/LICENSE-2.0\n",
       " *\n",
       " * Unless required by applicable law or agreed to in writing, software\n",
       " * distributed under the License is distributed on an \"AS IS\" BASIS,\n",
       " * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n",
       " * See the License for the specific language governing permissions and\n",
       " * limitations under the License.\n",
       " */\n",
       "\n",
       "/**\n",
       " *  Plotting of decision trees generated by TF-DF.\n",
       " *\n",
       " *  A tree is a recursive structure of node objects.\n",
       " *  A node contains one or more of the following components:\n",
       " *\n",
       " *    - A value: Representing the output of the node. If the node is not a leaf,\n",
       " *      the value is only present for analysis i.e. it is not used for\n",
       " *      predictions.\n",
       " *\n",
       " *    - A condition : For non-leaf nodes, the condition (also known as split)\n",
       " *      defines a binary test to branch to the positive or negative child.\n",
       " *\n",
       " *    - An explanation: Generally a plot showing the relation between the label\n",
       " *      and the condition to give insights about the effect of the condition.\n",
       " *\n",
       " *    - Two children : For non-leaf nodes, the children nodes. The first\n",
       " *      children (i.e. \"node.children[0]\") is the negative children (drawn in\n",
       " *      red). The second children is the positive one (drawn in green).\n",
       " *\n",
       " */\n",
       "\n",
       "/**\n",
       " * Plots a single decision tree into a DOM element.\n",
       " * @param {!options} options Dictionary of configurations.\n",
       " * @param {!tree} raw_tree Recursive tree structure.\n",
       " * @param {string} canvas_id Id of the output dom element.\n",
       " */\n",
       "function display_tree(options, raw_tree, canvas_id) {\n",
       "  console.log(options);\n",
       "\n",
       "  // Determine the node placement.\n",
       "  const tree_struct = d3.tree().nodeSize(\n",
       "      [options.node_y_offset, options.node_x_offset])(d3.hierarchy(raw_tree));\n",
       "\n",
       "  // Boundaries of the node placement.\n",
       "  let x_min = Infinity;\n",
       "  let x_max = -x_min;\n",
       "  let y_min = Infinity;\n",
       "  let y_max = -x_min;\n",
       "\n",
       "  tree_struct.each(d => {\n",
       "    if (d.x > x_max) x_max = d.x;\n",
       "    if (d.x < x_min) x_min = d.x;\n",
       "    if (d.y > y_max) y_max = d.y;\n",
       "    if (d.y < y_min) y_min = d.y;\n",
       "  });\n",
       "\n",
       "  // Size of the plot.\n",
       "  const width = y_max - y_min + options.node_x_size + options.margin * 2;\n",
       "  const height = x_max - x_min + options.node_y_size + options.margin * 2 +\n",
       "      options.node_y_offset - options.node_y_size;\n",
       "\n",
       "  const plot = d3.select(canvas_id);\n",
       "\n",
       "  // Tool tip\n",
       "  options.tooltip = plot.append('div')\n",
       "                        .attr('width', 100)\n",
       "                        .attr('height', 100)\n",
       "                        .style('padding', '4px')\n",
       "                        .style('background', '#fff')\n",
       "                        .style('box-shadow', '4px 4px 0px rgba(0,0,0,0.1)')\n",
       "                        .style('border', '1px solid black')\n",
       "                        .style('font-family', 'sans-serif')\n",
       "                        .style('font-size', options.font_size)\n",
       "                        .style('position', 'absolute')\n",
       "                        .style('z-index', '10')\n",
       "                        .attr('pointer-events', 'none')\n",
       "                        .style('display', 'none');\n",
       "\n",
       "  // Create canvas\n",
       "  const svg = plot.append('svg').attr('width', width).attr('height', height);\n",
       "  const graph =\n",
       "      svg.style('overflow', 'visible')\n",
       "          .append('g')\n",
       "          .attr('font-family', 'sans-serif')\n",
       "          .attr('font-size', options.font_size)\n",
       "          .attr(\n",
       "              'transform',\n",
       "              () => `translate(${options.margin},${\n",
       "                  - x_min + options.node_y_offset / 2 + options.margin})`);\n",
       "\n",
       "  // Plot bounding box.\n",
       "  if (options.show_plot_bounding_box) {\n",
       "    svg.append('rect')\n",
       "        .attr('width', width)\n",
       "        .attr('height', height)\n",
       "        .attr('fill', 'none')\n",
       "        .attr('stroke-width', 1.0)\n",
       "        .attr('stroke', 'black');\n",
       "  }\n",
       "\n",
       "  // Draw the edges.\n",
       "  display_edges(options, graph, tree_struct);\n",
       "\n",
       "  // Draw the nodes.\n",
       "  display_nodes(options, graph, tree_struct);\n",
       "}\n",
       "\n",
       "/**\n",
       " * Draw the nodes of the tree.\n",
       " * @param {!options} options Dictionary of configurations.\n",
       " * @param {!graph} graph D3 search handle containing the graph.\n",
       " * @param {!tree_struct} tree_struct Structure of the tree (node placement,\n",
       " *     data, etc.).\n",
       " */\n",
       "function display_nodes(options, graph, tree_struct) {\n",
       "  const nodes = graph.append('g')\n",
       "                    .selectAll('g')\n",
       "                    .data(tree_struct.descendants())\n",
       "                    .join('g')\n",
       "                    .attr('transform', d => `translate(${d.y},${d.x})`);\n",
       "\n",
       "  nodes.append('rect')\n",
       "      .attr('x', 0.5)\n",
       "      .attr('y', 0.5)\n",
       "      .attr('width', options.node_x_size)\n",
       "      .attr('height', options.node_y_size)\n",
       "      .attr('stroke', 'lightgrey')\n",
       "      .attr('stroke-width', 1)\n",
       "      .attr('fill', 'white')\n",
       "      .attr('y', -options.node_y_size / 2);\n",
       "\n",
       "  // Brackets on the right of condition nodes without children.\n",
       "  non_leaf_node_without_children =\n",
       "      nodes.filter(node => node.data.condition != null && node.children == null)\n",
       "          .append('g')\n",
       "          .attr('transform', `translate(${options.node_x_size},0)`);\n",
       "\n",
       "  non_leaf_node_without_children.append('path')\n",
       "      .attr('d', 'M0,0 C 10,0 0,10 10,10')\n",
       "      .attr('fill', 'none')\n",
       "      .attr('stroke-width', 1.0)\n",
       "      .attr('stroke', '#F00');\n",
       "\n",
       "  non_leaf_node_without_children.append('path')\n",
       "      .attr('d', 'M0,0 C 10,0 0,-10 10,-10')\n",
       "      .attr('fill', 'none')\n",
       "      .attr('stroke-width', 1.0)\n",
       "      .attr('stroke', '#0F0');\n",
       "\n",
       "  const node_content = nodes.append('g').attr(\n",
       "      'transform',\n",
       "      `translate(0,${options.node_padding - options.node_y_size / 2})`);\n",
       "\n",
       "  node_content.append(node => create_node_element(options, node));\n",
       "}\n",
       "\n",
       "/**\n",
       " * Creates the D3 content for a single node.\n",
       " * @param {!options} options Dictionary of configurations.\n",
       " * @param {!node} node Node to draw.\n",
       " * @return {!d3} D3 content.\n",
       " */\n",
       "function create_node_element(options, node) {\n",
       "  // Output accumulator.\n",
       "  let output = {\n",
       "    // Content to draw.\n",
       "    content: d3.create('svg:g'),\n",
       "    // Vertical offset to the next element to draw.\n",
       "    vertical_offset: 0\n",
       "  };\n",
       "\n",
       "  // Conditions.\n",
       "  if (node.data.condition != null) {\n",
       "    display_condition(options, node.data.condition, output);\n",
       "  }\n",
       "\n",
       "  // Values.\n",
       "  if (node.data.value != null) {\n",
       "    display_value(options, node.data.value, output);\n",
       "  }\n",
       "\n",
       "  // Explanations.\n",
       "  if (node.data.explanation != null) {\n",
       "    display_explanation(options, node.data.explanation, output);\n",
       "  }\n",
       "\n",
       "  return output.content.node();\n",
       "}\n",
       "\n",
       "\n",
       "/**\n",
       " * Adds a single line of text inside of a node.\n",
       " * @param {!options} options Dictionary of configurations.\n",
       " * @param {string} text Text to display.\n",
       " * @param {!output} output Output display accumulator.\n",
       " */\n",
       "function display_node_text(options, text, output) {\n",
       "  output.content.append('text')\n",
       "      .attr('x', options.node_padding)\n",
       "      .attr('y', output.vertical_offset)\n",
       "      .attr('alignment-baseline', 'hanging')\n",
       "      .text(text);\n",
       "  output.vertical_offset += 10;\n",
       "}\n",
       "\n",
       "/**\n",
       " * Adds a single line of text inside of a node with a tooltip.\n",
       " * @param {!options} options Dictionary of configurations.\n",
       " * @param {string} text Text to display.\n",
       " * @param {string} tooltip Text in the Tooltip.\n",
       " * @param {!output} output Output display accumulator.\n",
       " */\n",
       "function display_node_text_with_tooltip(options, text, tooltip, output) {\n",
       "  const item = output.content.append('text')\n",
       "                   .attr('x', options.node_padding)\n",
       "                   .attr('alignment-baseline', 'hanging')\n",
       "                   .text(text);\n",
       "\n",
       "  add_tooltip(options, item, () => tooltip);\n",
       "  output.vertical_offset += 10;\n",
       "}\n",
       "\n",
       "/**\n",
       " * Adds a tooltip to a dom element.\n",
       " * @param {!options} options Dictionary of configurations.\n",
       " * @param {!dom} target Dom element to equip with a tooltip.\n",
       " * @param {!func} get_content Generates the html content of the tooltip.\n",
       " */\n",
       "function add_tooltip(options, target, get_content) {\n",
       "  function show(d) {\n",
       "    options.tooltip.style('display', 'block');\n",
       "    options.tooltip.html(get_content());\n",
       "  }\n",
       "\n",
       "  function hide(d) {\n",
       "    options.tooltip.style('display', 'none');\n",
       "  }\n",
       "\n",
       "  function move(d) {\n",
       "    options.tooltip.style('display', 'block');\n",
       "    options.tooltip.style('left', (d.pageX + 5) + 'px');\n",
       "    options.tooltip.style('top', d.pageY + 'px');\n",
       "  }\n",
       "\n",
       "  target.on('mouseover', show);\n",
       "  target.on('mouseout', hide);\n",
       "  target.on('mousemove', move);\n",
       "}\n",
       "\n",
       "/**\n",
       " * Adds a condition inside of a node.\n",
       " * @param {!options} options Dictionary of configurations.\n",
       " * @param {!condition} condition Condition to display.\n",
       " * @param {!output} output Output display accumulator.\n",
       " */\n",
       "function display_condition(options, condition, output) {\n",
       "  threshold_format = d3.format('r');\n",
       "\n",
       "  if (condition.type === 'IS_MISSING') {\n",
       "    display_node_text(options, `${condition.attribute} is missing`, output);\n",
       "    return;\n",
       "  }\n",
       "\n",
       "  if (condition.type === 'IS_TRUE') {\n",
       "    display_node_text(options, `${condition.attribute} is true`, output);\n",
       "    return;\n",
       "  }\n",
       "\n",
       "  if (condition.type === 'NUMERICAL_IS_HIGHER_THAN') {\n",
       "    format = d3.format('r');\n",
       "    display_node_text(\n",
       "        options,\n",
       "        `${condition.attribute} >= ${threshold_format(condition.threshold)}`,\n",
       "        output);\n",
       "    return;\n",
       "  }\n",
       "\n",
       "  if (condition.type === 'CATEGORICAL_IS_IN') {\n",
       "    display_node_text_with_tooltip(\n",
       "        options, `${condition.attribute} in [...]`,\n",
       "        `${condition.attribute} in [${condition.mask}]`, output);\n",
       "    return;\n",
       "  }\n",
       "\n",
       "  if (condition.type === 'CATEGORICAL_SET_CONTAINS') {\n",
       "    display_node_text_with_tooltip(\n",
       "        options, `${condition.attribute} intersect [...]`,\n",
       "        `${condition.attribute} intersect [${condition.mask}]`, output);\n",
       "    return;\n",
       "  }\n",
       "\n",
       "  if (condition.type === 'NUMERICAL_SPARSE_OBLIQUE') {\n",
       "    display_node_text_with_tooltip(\n",
       "        options, `Sparse oblique split...`,\n",
       "        `[${condition.attributes}]*[${condition.weights}]>=${\n",
       "            threshold_format(condition.threshold)}`,\n",
       "        output);\n",
       "    return;\n",
       "  }\n",
       "\n",
       "  display_node_text(\n",
       "      options, `Non supported condition ${condition.type}`, output);\n",
       "}\n",
       "\n",
       "/**\n",
       " * Adds a value inside of a node.\n",
       " * @param {!options} options Dictionary of configurations.\n",
       " * @param {!value} value Value to display.\n",
       " * @param {!output} output Output display accumulator.\n",
       " */\n",
       "function display_value(options, value, output) {\n",
       "  if (value.type === 'PROBABILITY') {\n",
       "    const left_margin = 0;\n",
       "    const right_margin = 50;\n",
       "    const plot_width = options.node_x_size - options.node_padding * 2 -\n",
       "        left_margin - right_margin;\n",
       "\n",
       "    let cusum = Array.from(d3.cumsum(value.distribution));\n",
       "    cusum.unshift(0);\n",
       "    const distribution_plot = output.content.append('g').attr(\n",
       "        'transform', `translate(0,${output.vertical_offset + 0.5})`);\n",
       "\n",
       "    distribution_plot.selectAll('rect')\n",
       "        .data(value.distribution)\n",
       "        .join('rect')\n",
       "        .attr('height', 10)\n",
       "        .attr(\n",
       "            'x',\n",
       "            (d, i) =>\n",
       "                (cusum[i] * plot_width + left_margin + options.node_padding))\n",
       "        .attr('width', (d, i) => d * plot_width)\n",
       "        .style('fill', (d, i) => d3.schemeSet1[i]);\n",
       "\n",
       "    const num_examples =\n",
       "        output.content.append('g')\n",
       "            .attr('transform', `translate(0,${output.vertical_offset})`)\n",
       "            .append('text')\n",
       "            .attr('x', options.node_x_size - options.node_padding)\n",
       "            .attr('alignment-baseline', 'hanging')\n",
       "            .attr('text-anchor', 'end')\n",
       "            .text(`(${value.num_examples})`);\n",
       "\n",
       "    const distribution_details = d3.create('ul');\n",
       "    distribution_details.selectAll('li')\n",
       "        .data(value.distribution)\n",
       "        .join('li')\n",
       "        .append('span')\n",
       "        .text(\n",
       "            (d, i) =>\n",
       "                'class ' + i + ': ' + d3.format('.3%')(value.distribution[i]));\n",
       "\n",
       "    add_tooltip(options, distribution_plot, () => distribution_details.html());\n",
       "    add_tooltip(options, num_examples, () => 'Number of examples');\n",
       "\n",
       "    output.vertical_offset += 10;\n",
       "    return;\n",
       "  }\n",
       "\n",
       "  if (value.type === 'REGRESSION') {\n",
       "    display_node_text(\n",
       "        options,\n",
       "        'value: ' + d3.format('r')(value.value) + ` (` +\n",
       "            d3.format('.6')(value.num_examples) + `)`,\n",
       "        output);\n",
       "    return;\n",
       "  }\n",
       "\n",
       "  display_node_text(options, `Non supported value ${value.type}`, output);\n",
       "}\n",
       "\n",
       "/**\n",
       " * Adds an explanation inside of a node.\n",
       " * @param {!options} options Dictionary of configurations.\n",
       " * @param {!explanation} explanation Explanation to display.\n",
       " * @param {!output} output Output display accumulator.\n",
       " */\n",
       "function display_explanation(options, explanation, output) {\n",
       "  // Margin before the explanation.\n",
       "  output.vertical_offset += 10;\n",
       "\n",
       "  display_node_text(\n",
       "      options, `Non supported explanation ${explanation.type}`, output);\n",
       "}\n",
       "\n",
       "\n",
       "/**\n",
       " * Draw the edges of the tree.\n",
       " * @param {!options} options Dictionary of configurations.\n",
       " * @param {!graph} graph D3 search handle containing the graph.\n",
       " * @param {!tree_struct} tree_struct Structure of the tree (node placement,\n",
       " *     data, etc.).\n",
       " */\n",
       "function display_edges(options, graph, tree_struct) {\n",
       "  // Draw an edge between a parent and a child node with a bezier.\n",
       "  function draw_single_edge(d) {\n",
       "    return 'M' + (d.source.y + options.node_x_size) + ',' + d.source.x + ' C' +\n",
       "        (d.source.y + options.node_x_size + options.edge_rounding) + ',' +\n",
       "        d.source.x + ' ' + (d.target.y - options.edge_rounding) + ',' +\n",
       "        d.target.x + ' ' + d.target.y + ',' + d.target.x;\n",
       "  }\n",
       "\n",
       "  graph.append('g')\n",
       "      .attr('fill', 'none')\n",
       "      .attr('stroke-width', 1.2)\n",
       "      .selectAll('path')\n",
       "      .data(tree_struct.links())\n",
       "      .join('path')\n",
       "      .attr('d', draw_single_edge)\n",
       "      .attr(\n",
       "          'stroke', d => (d.target === d.source.children[0]) ? '#0F0' : '#F00');\n",
       "}\n",
       "\n",
       "display_tree({\"margin\": 10, \"node_x_size\": 160, \"node_y_size\": 28, \"node_x_offset\": 180, \"node_y_offset\": 33, \"font_size\": 10, \"edge_rounding\": 20, \"node_padding\": 2, \"show_plot_bounding_box\": false}, {\"value\": {\"type\": \"PROBABILITY\", \"distribution\": [0.09876666666666667, 0.10908333333333334, 0.09856666666666666, 0.10136666666666666, 0.09851666666666667, 0.09096666666666667, 0.09908333333333333, 0.10536666666666666, 0.0995, 0.09878333333333333], \"num_examples\": 60000.0}, \"condition\": {\"type\": \"NUMERICAL_IS_HIGHER_THAN\", \"attribute\": \"data:0.6\", \"threshold\": 0.5}, \"children\": [{\"value\": {\"type\": \"PROBABILITY\", \"distribution\": [0.07358374384236453, 0.007927955665024631, 0.15047721674876846, 0.002232142857142857, 0.3073429802955665, 0.022706280788177338, 0.40370997536945813, 0.006542487684729064, 0.010929802955665025, 0.014547413793103448], \"num_examples\": 12992.0}, \"condition\": {\"type\": \"NUMERICAL_IS_HIGHER_THAN\", \"attribute\": \"data:0.27\", \"threshold\": 0.5}, \"children\": [{\"value\": {\"type\": \"PROBABILITY\", \"distribution\": [0.06701807228915663, 0.000251004016064257, 0.07705823293172691, 0.0015060240963855422, 0.6892570281124498, 0.03112449799196787, 0.06300200803212852, 0.01606425702811245, 0.018323293172690762, 0.03639558232931727], \"num_examples\": 3984.0}, \"condition\": {\"type\": \"NUMERICAL_IS_HIGHER_THAN\", \"attribute\": \"data:0.15\", \"threshold\": 0.5}, \"children\": [{\"value\": {\"type\": \"PROBABILITY\", \"distribution\": [0.39293598233995586, 0.0, 0.02869757174392936, 0.0, 0.08609271523178808, 0.271523178807947, 0.07505518763796909, 0.12141280353200883, 0.006622516556291391, 0.017660044150110375], \"num_examples\": 453.0}, \"condition\": {\"type\": \"NUMERICAL_IS_HIGHER_THAN\", \"attribute\": \"data:0.28\", \"threshold\": 0.5}}, {\"value\": {\"type\": \"PROBABILITY\", \"distribution\": [0.02520532427074483, 0.0002832058906825262, 0.08326253186066271, 0.0016992353440951572, 0.7666383460775984, 0.0002832058906825262, 0.06145567827810818, 0.002548853016142736, 0.019824412347776835, 0.03879920702350609], \"num_examples\": 3531.0}, \"condition\": {\"type\": \"NUMERICAL_IS_HIGHER_THAN\", \"attribute\": \"data:0.28\", \"threshold\": 0.5}}]}, {\"value\": {\"type\": \"PROBABILITY\", \"distribution\": [0.07648756660746003, 0.011323268206039076, 0.18294849023090587, 0.0025532859680284193, 0.13843250444049734, 0.018983126110124333, 0.5543960923623446, 0.002331261101243339, 0.007659857904085257, 0.004884547069271759], \"num_examples\": 9008.0}, \"condition\": {\"type\": \"NUMERICAL_IS_HIGHER_THAN\", \"attribute\": \"data:0.39\", \"threshold\": -0.5}, \"children\": [{\"value\": {\"type\": \"PROBABILITY\", \"distribution\": [0.07047648230427456, 0.015627393902252183, 0.2454420101118431, 0.003064194882794546, 0.026352075992033094, 0.022828251876819364, 0.6041060211429446, 0.0029109851386548186, 0.008426535927685, 0.0007660487206986365], \"num_examples\": 6527.0}, \"condition\": {\"type\": \"NUMERICAL_IS_HIGHER_THAN\", \"attribute\": \"data:0.49\", \"threshold\": 0.5}}, {\"value\": {\"type\": \"PROBABILITY\", \"distribution\": [0.09230149133413947, 0.0, 0.018540910923014912, 0.0012091898428053204, 0.4332930270052398, 0.00886739218057235, 0.42361950826279726, 0.0008061265618702137, 0.005642885933091495, 0.015719467956469165], \"num_examples\": 2481.0}, \"condition\": {\"type\": \"NUMERICAL_IS_HIGHER_THAN\", \"attribute\": \"data:0.6\", \"threshold\": 1.5}}]}]}, {\"value\": {\"type\": \"PROBABILITY\", \"distribution\": [0.10572668481960518, 0.13704050374404356, 0.08421970728386657, 0.1287653165418652, 0.04080156569094622, 0.10983236895847516, 0.014891082368958475, 0.13267954390742, 0.12397889720898571, 0.1220643294758339], \"num_examples\": 47008.0}, \"condition\": {\"type\": \"NUMERICAL_IS_HIGHER_THAN\", \"attribute\": \"data:0.15\", \"threshold\": -0.5}, \"children\": [{\"value\": {\"type\": \"PROBABILITY\", \"distribution\": [0.12568306010928962, 0.16764713572306325, 0.06552147880879546, 0.13880827254425185, 0.046905639658012394, 0.1280100400031375, 0.01772688053965017, 0.1583653619891756, 0.03153188485371402, 0.11980024577091014], \"num_examples\": 38247.0}, \"condition\": {\"type\": \"NUMERICAL_IS_HIGHER_THAN\", \"attribute\": \"data:0.27\", \"threshold\": 0.5}, \"children\": [{\"value\": {\"type\": \"PROBABILITY\", \"distribution\": [0.10859024791876315, 0.0028359710913914557, 0.018845485316988382, 0.00786753270515049, 0.06047022230354039, 0.130180221388711, 0.0015552099533437014, 0.42310859024791875, 0.01655841185618882, 0.22998810721800383], \"num_examples\": 10931.0}, \"condition\": {\"type\": \"NUMERICAL_IS_HIGHER_THAN\", \"attribute\": \"data:0.28\", \"threshold\": 1.5}}, {\"value\": {\"type\": \"PROBABILITY\", \"distribution\": [0.13252306340606237, 0.2335993556889735, 0.08419973641821643, 0.1912066188314541, 0.04147752233123444, 0.12714160199150681, 0.024198272074974374, 0.052423488065602576, 0.03752379557768341, 0.07570654561429199], \"num_examples\": 27316.0}, \"condition\": {\"type\": \"NUMERICAL_IS_HIGHER_THAN\", \"attribute\": \"data:0.6\", \"threshold\": -0.5}}]}, {\"value\": {\"type\": \"PROBABILITY\", \"distribution\": [0.018605182056842827, 0.003424266636228741, 0.1658486474146787, 0.08492181257847278, 0.014153635429745463, 0.030475973062435796, 0.0025111288665677434, 0.020545599817372445, 0.5275653464216413, 0.13194840771601415], \"num_examples\": 8761.0}, \"condition\": {\"type\": \"NUMERICAL_IS_HIGHER_THAN\", \"attribute\": \"data:0.27\", \"threshold\": 0.5}, \"children\": [{\"value\": {\"type\": \"PROBABILITY\", \"distribution\": [0.01973916108565386, 0.0010574550581600281, 0.08036658442016215, 0.036658442016214314, 0.03947832217130772, 0.018329221008107157, 0.0, 0.053577722946774764, 0.386323581247797, 0.36446951004582306], \"num_examples\": 2837.0}, \"condition\": {\"type\": \"NUMERICAL_IS_HIGHER_THAN\", \"attribute\": \"data:0.49\", \"threshold\": 0.5}}, {\"value\": {\"type\": \"PROBABILITY\", \"distribution\": [0.018062120189061445, 0.004557731262660365, 0.20678595543551653, 0.10803511141120864, 0.002025658338960162, 0.036293045239702906, 0.003713706954760297, 0.004726536124240378, 0.5952059419311276, 0.020594193112761647], \"num_examples\": 5924.0}, \"condition\": {\"type\": \"NUMERICAL_IS_HIGHER_THAN\", \"attribute\": \"data:0.49\", \"threshold\": 0.5}}]}]}]}, \"#tree_plot_83f506b8bfe04b3f9caa3f506ee25869\")\n",
       "</script>\n"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from IPython.core.display import HTML\n",
    "HTML(html)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "collapsed_sections": [],
   "name": "data_compression.ipynb",
   "toc_visible": true
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
