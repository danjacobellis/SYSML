{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "b012b6ad-7833-4eba-a34a-2cce64128ff0",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "import numpy as np\n",
    "import PIL\n",
    "from imgnet32y_RDAE import *\n",
    "import matplotlib.pyplot as plt\n",
    "from functools import wraps\n",
    "from time import time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "a6c61727-c3be-4062-8509-04bf03b3d1e3",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def timing(f):\n",
    "    @wraps(f)\n",
    "    def wrap(*args, **kw):\n",
    "        ts = time()\n",
    "        result = f(*args, **kw)\n",
    "        te = time()\n",
    "        print('func:%r args:[%r, %r] took: %2.4f sec' % \\\n",
    "          (f.__name__, args, kw, te-ts))\n",
    "        return result\n",
    "    return wrap"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "81449457-77df-4c2e-bcd0-e4ada4b09b8a",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "IMG_SIZE = 32;\n",
    "N_CHANNELS = 1;\n",
    "ALPHA = 0.125;\n",
    "batch_size = 32;\n",
    "NUM_CLASSES = 10;\n",
    "size = (IMG_SIZE,IMG_SIZE);\n",
    "\n",
    "(ds_train, ds_test), ds_info = tfds.load(\n",
    "    \"imagenette\", split=['train','validation'], with_info=True, as_supervised=True\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "31ca1342-7bf5-4020-ba6e-77e5ed99cb77",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def resize(image, label):\n",
    "    resized = tf.image.resize(image, size)\n",
    "    resized = tf.image.rgb_to_grayscale(resized)\n",
    "    return resized, label\n",
    "def onehot(image, label):\n",
    "    label = tf.one_hot(label, NUM_CLASSES)\n",
    "    return image, label"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "373d977b-3ef5-45cc-bd44-4256453dd721",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "ds_train = ds_train.map(resize, num_parallel_calls=8)\n",
    "ds_train = ds_train.map(onehot, num_parallel_calls=8)\n",
    "ds_train = ds_train.batch(batch_size=batch_size, drop_remainder=True)\n",
    "\n",
    "ds_test = ds_test.map(resize, num_parallel_calls=8)\n",
    "ds_test = ds_test.map(onehot, num_parallel_calls=8)\n",
    "ds_test = ds_test.batch(batch_size=batch_size, drop_remainder=True)\n",
    "\n",
    "ds_train = ds_train.prefetch(tf.data.AUTOTUNE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "f5823565-76dd-4703-a067-525267835ca2",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - ETA: 0s - loss: 2262.4705 - distortion_loss: 0.9994 - rate_loss: 263.6897 - distortion_pass_through_loss: 0.9994 - rate_pass_through_loss: 263.6897"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:Computing quantization offsets using offset heuristic within a tf.function. Ideally, the offset heuristic should only be used to determine offsets once after training. Depending on the prior, estimating the offset might be computationally expensive.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 4s 4s/step - loss: 2262.4705 - distortion_loss: 0.9994 - rate_loss: 263.6897 - distortion_pass_through_loss: 0.9994 - rate_pass_through_loss: 263.6897 - val_loss: 2256.1201 - val_distortion_loss: 0.9981 - val_rate_loss: 259.9435 - val_distortion_pass_through_loss: 0.9981 - val_rate_pass_through_loss: 259.9435\n"
     ]
    }
   ],
   "source": [
    "compressor,decompressor = load_pretrained_RDAE()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "2bd026fd-08be-4928-92b8-b74c6d5ba191",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-04-18 13:48:54.269115: I tensorflow/core/common_runtime/executor.cc:1197] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor 'Placeholder/_4' with dtype int64 and shape [16]\n",
      "\t [[{{node Placeholder/_4}}]]\n",
      "2023-04-18 13:48:54.270159: I tensorflow/core/common_runtime/executor.cc:1197] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor 'Placeholder/_3' with dtype int64 and shape [16]\n",
      "\t [[{{node Placeholder/_3}}]]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "func:'encode' args:[(), {}] took: 4.8601 sec\n"
     ]
    }
   ],
   "source": [
    "@timing\n",
    "def encode():\n",
    "    C = []\n",
    "    for X,y in ds_train.take(-1):\n",
    "        strings, entropies = compressor(X)\n",
    "        C.append(strings)\n",
    "    C = tf.reshape(tf.stack(C),(9440))\n",
    "    np.save('imagenette_32y',np.array(C))\n",
    "encode()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "id": "f96575b8-dcfd-41ea-bf8a-374d55ac8a15",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "ContinuousBatchedEntropyModel.decompress() missing 1 required positional argument: 'broadcast_shape'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[69], line 5\u001b[0m\n\u001b[1;32m      3\u001b[0m     C \u001b[38;5;241m=\u001b[39m np\u001b[38;5;241m.\u001b[39mload(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mimagenette_32y.npy\u001b[39m\u001b[38;5;124m'\u001b[39m,allow_pickle\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m)\n\u001b[1;32m      4\u001b[0m     D \u001b[38;5;241m=\u001b[39m decompressor\u001b[38;5;241m.\u001b[39mentropy_model\u001b[38;5;241m.\u001b[39mdecompress(C)\n\u001b[0;32m----> 5\u001b[0m \u001b[43mpartial_decode\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n",
      "Cell \u001b[0;32mIn[9], line 5\u001b[0m, in \u001b[0;36mtiming.<locals>.wrap\u001b[0;34m(*args, **kw)\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[38;5;129m@wraps\u001b[39m(f)\n\u001b[1;32m      3\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mwrap\u001b[39m(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkw):\n\u001b[1;32m      4\u001b[0m     ts \u001b[38;5;241m=\u001b[39m time()\n\u001b[0;32m----> 5\u001b[0m     result \u001b[38;5;241m=\u001b[39m \u001b[43mf\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkw\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m      6\u001b[0m     te \u001b[38;5;241m=\u001b[39m time()\n\u001b[1;32m      7\u001b[0m     \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mfunc:\u001b[39m\u001b[38;5;132;01m%r\u001b[39;00m\u001b[38;5;124m args:[\u001b[39m\u001b[38;5;132;01m%r\u001b[39;00m\u001b[38;5;124m, \u001b[39m\u001b[38;5;132;01m%r\u001b[39;00m\u001b[38;5;124m] took: \u001b[39m\u001b[38;5;132;01m%2.4f\u001b[39;00m\u001b[38;5;124m sec\u001b[39m\u001b[38;5;124m'\u001b[39m \u001b[38;5;241m%\u001b[39m \\\n\u001b[1;32m      8\u001b[0m       (f\u001b[38;5;241m.\u001b[39m\u001b[38;5;18m__name__\u001b[39m, args, kw, te\u001b[38;5;241m-\u001b[39mts))\n",
      "Cell \u001b[0;32mIn[69], line 4\u001b[0m, in \u001b[0;36mpartial_decode\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[38;5;129m@timing\u001b[39m\n\u001b[1;32m      2\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mpartial_decode\u001b[39m():\n\u001b[1;32m      3\u001b[0m     C \u001b[38;5;241m=\u001b[39m np\u001b[38;5;241m.\u001b[39mload(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mimagenette_32y.npy\u001b[39m\u001b[38;5;124m'\u001b[39m,allow_pickle\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m)\n\u001b[0;32m----> 4\u001b[0m     D \u001b[38;5;241m=\u001b[39m \u001b[43mdecompressor\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mentropy_model\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mdecompress\u001b[49m\u001b[43m(\u001b[49m\u001b[43mC\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/.local/lib/python3.10/site-packages/tensorflow/python/module/module.py:311\u001b[0m, in \u001b[0;36mModule.with_name_scope.<locals>.method_with_name_scope\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m    309\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mmethod_with_name_scope\u001b[39m(\u001b[38;5;28mself\u001b[39m, \u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs):\n\u001b[1;32m    310\u001b[0m   \u001b[38;5;28;01mwith\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mname_scope:\n\u001b[0;32m--> 311\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mmethod\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[0;31mTypeError\u001b[0m: ContinuousBatchedEntropyModel.decompress() missing 1 required positional argument: 'broadcast_shape'"
     ]
    }
   ],
   "source": [
    "@timing\n",
    "def partial_decode():\n",
    "    C = np.load('imagenette_32y.npy',allow_pickle=True)\n",
    "    D = decompressor.entropy_model.decompress(C)\n",
    "partial_decode()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f57ba901-2144-4dae-9a8f-8c2ef18fbf36",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "decompressor.entropy_model.decompress(C,broadcast_shape=(128))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "id": "b2230273-2f5d-42ae-bbdd-58b4b502b70a",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "func:'full_decode' args:[(), {}] took: 0.0403 sec\n"
     ]
    }
   ],
   "source": [
    "@timing\n",
    "def full_decode():\n",
    "    C = np.load('imagenette_32y.npy',allow_pickle=True)\n",
    "    D = decompressor(C)\n",
    "full_decode()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6465607d-f9e8-4800-aa2b-1bc1d3662350",
   "metadata": {},
   "outputs": [],
   "source": [
    "# \n",
    "# for i_example in range(5):\n",
    "#     x = X[i_example].numpy()\n",
    "#     x = tf.convert_to_tensor(x.astype(np.uint8))\n",
    "#     display_tf(x)\n",
    "#     display_tf(reconstructions[i_example])\n",
    "#     pass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ad2f819c-1b39-4afb-a6f4-09f890e1897c",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "MBNet = MobileNetV2(\n",
    "    include_top=True,\n",
    "    weights=None,\n",
    "    alpha=ALPHA,\n",
    "    classes=10,\n",
    "    input_shape=(IMG_SIZE,IMG_SIZE,N_CHANNELS),\n",
    ")\n",
    "model = MBNet\n",
    "model.compile(\n",
    "    optimizer=\"adam\", loss=\"categorical_crossentropy\", metrics=[\"accuracy\"]\n",
    ")\n",
    "print(model.layers[0].get_input_shape_at(0))\n",
    "print(model.layers[-1].get_output_shape_at(0))\n",
    "print(np.size(model.layers))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "30394fbc-f779-4ab0-b51f-f0e203722fe4",
   "metadata": {},
   "source": [
    "13% GPU utilization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7dc76fd1-bba0-4523-9a09-ebc7be9e32cd",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "epochs = 30\n",
    "hist = model.fit(ds_train, epochs=epochs, validation_data=ds_test, verbose=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6f8e7d0f-9257-44ae-8e8b-5271c1f47ebf",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "plt.plot(hist.history['accuracy'])\n",
    "plt.plot(hist.history['val_accuracy'])\n",
    "plt.xlabel('Epochs')\n",
    "plt.ylabel('Accuracy')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
